---
title: "RIOS Research - Inclusive Teaching Text Analysis - Data Cleaning"
author: "Sokona Mangane"
date: "2022-12-14"
output:
  html_document
---

# Introduction

My name is Sokona Mangane and I'm from Brooklyn, NY. I'm a senior at Bates College, majoring in Mathematics, and minoring in Digital and Computational Studies. I manually entered the title, Inclusive Teaching section, DOI, word count, etc., for each article from the website [CourseSource](https://qubeshub.org/community/groups/coursesource/) into an excel sheet. I imported the csv in R and did some some data cleaning in preparation for analysis. Along with my colleague, Yuhao Zhao, and research mentor, Professor Carrie Diaz-Eaton, we manually verified if all 4,464 distinct words in the *Inclusive Teaching Section* should be labeled as JEDI (looked at the context of the words as required) and imported it into R as well. Presented below is code of how we used this manually verified JEDI keywords list for our data set. 

# Setup/Data Cleaning

I import the necessary packages for analysis.

```{r install and load packages, message=FALSE, warning=FALSE}

# knitr::opts_chunks$set(warning = FALSE, message = FALSE)

# store string containing all required packages
my_packages <- c('varhandle', 'skimr', 'tidyverse', 'tidytext', 'stopwords', "wordcloud", "reshape2", "ggraph", "kableExtra",'readr', 'dplyr', "igraph","SnowballC", "knitr", "git2rdata")

# store all installed packages
ya_installed <- library()$results[,1]

# check whether required packages are already installed and grab only those that still need installation
need_install<-my_packages[!(my_packages %in% ya_installed)]

# install required packages
lapply(need_install, install.packages, character.only = TRUE)

#similar process as above, but loading the packages

# store all installed packages
ya_loaded <- (.packages())

# check whether required packages are already installed and grab only those that still need installation
need_load<-my_packages[!(my_packages %in% ya_loaded)]

# load required packages
lapply(need_load, require, character.only = TRUE)

```

I import the dataset, as well as the JEDI keywords dataset.

```{r import data, warning=FALSE, message=FALSE}

# import dataset from excel
rios_data <- read_csv("https://raw.githubusercontent.com/smsokona/RIOS---CourseSource-Research/master/Data%20Cleaning/Data%20for%20Import/RIOS%20Research%20-%20Course%20Source%20-%20Sheet1%202.csv")

# list of JEDI/DEI keywords given by research mentor Dr. Diaz Eaton; Used in another paper and will be used below to check for DEI related words in every section
dei_keywords <- read_csv("https://raw.githubusercontent.com/smsokona/RIOS---CourseSource-Research/master/Data%20Cleaning/Data%20for%20Import/SJEDI_words%202022-12-20%2018_03_42.csv")

```


# Data Manipulation

I fixed any errors and added some variables to the original excel data set.

```{r manipulate original df}

# fix human error for one article
rios_data$`Inclusive Teaching  included?`[12] = "No"

# remove any article that that doesn't have an inclusive teaching section (30 articles)
rios_data <- rios_data %>% 
  filter(`Inclusive Teaching  included?` != "No")

# arrange years 
rios_data <- rios_data %>%
  arrange(desc(Year))

# create a new column which numbers each article (most recent article: 286)
rios_data$article_num <- c(nrow(rios_data):1)
                    
# create column that groups based on the shift (2014-2018 and 2019-2022)       
rios_data <- rios_data %>% 
  mutate(`Group Year` = case_when(
    as.numeric(Year) <= 2018 ~ "2014 - 2018",
    as.numeric(Year) > 2018 ~ "2019 - 2022"
  )) 

# replace NAs with "No" in 'Attended Workshop?' column
rios_data <- rios_data %>% 
  mutate(`Attended Workshop?` = case_when(
    `Attended Workshop?` == "yes" ~ "Yes",
    TRUE ~ "No"
  )) 

# remove unnecessary columns
rios_data <- rios_data[,-c(11:14)]

```

# Creating Tokenized Dataframe 

I create a dataframe where each word from the paragraph in the `Inlcusive Teaching Description` column is "un-nested" into it's own row. 

```{r create, manipulate, and clean token df}

# split the text from the `inclusive teaching description` column into a one-token-per-row format
rios_data_tokenizedit <- rios_data %>%
  unnest_tokens(output = inclusive_teach_tokens, input = `Inclusive Teaching Description`)

# store unnecessary punctuation, digits, or "stopwords" in a vector for removal
strings <- c("[:punct:]", "[:digit:]","\\(","\\)")
stopwords_vec <- stopwords(language = "en")
stopwords_vec <- stopwords_vec[-c(165:167)]

# remove ~747 rows of punctuation and digits
rios_data_tokenizedit <- rios_data_tokenizedit %>%
  filter(!str_detect(inclusive_teach_tokens, paste(strings, collapse = "|")))

# remove ~19,470 rows of english lang. stopwords
rios_data_tokenizedit <- rios_data_tokenizedit %>%
  filter(!inclusive_teach_tokens %in% stopwords_vec) 
```

## Verification of DEI Keywords

I've created a variable which contains diversity related words (I manually checked and pulled these from the keywords column) and then combined it with the `dei_keywords` dataframe I imported. Keep in mind that the `dei_keywords` dataframe is stemmed and the words I manually added aren't.

```{r manipulate deikeywords}

# create vector of DEI related words and store in a variable
diversity_related <- c("diversity", "bias", "confirmation bias", "cognitive bias", "social justice", "broader impacts", "racism", "identity", "equity", "inclusivity", "environmental justice", "inclusion", "belonging")

# add the vector above to the CSV dei_keywords
for (x in 1:13){
  dei_keywords[nrow(dei_keywords) + 1,] = diversity_related[x]
}

```

I export a CSV of all distinct words in the inclusive teaching section for manual verification (whether or not this should be labeled JEDI or not).

```{r deikeywords verification, eval=FALSE}

# create a dataframe of all the unique words a.k.a. "tokens" in the inclusive teaching sections
allwords <- as.data.frame(unique(rios_data_tokenizedit$inclusive_teach_tokens))

# create a column of logical values, if the unique words above match any of the JEDI/DEI keywords
allwords$deirelated <- sapply(allwords$`unique(rios_data_tokenizedit$inclusive_teach_tokens)`, function(x) any(sapply(dei_keywords, str_detect, string = x)))

# export for review
write_csv(allwords, "DEIRelated.csv")
```

# Tokenized Dataframe Manipulation

After manual verification, I import the verified JEDI keyword list back into R. I repeat the process above, of creating a DEI related column, using this list. I also do some additional data manipulation.

``` {r manipulate, warning=FALSE, message=FALSE}

# import manually verified list of JEDI words and filter for JEDI words only
JEDI_keywords_df <- read_csv("https://raw.githubusercontent.com/smsokona/RIOS---CourseSource-Research/master/Data%20Cleaning/Data%20for%20Import/cleanedITwords%20-%20cleanedITwords.csv") %>% 
  filter(Carrie == "JEDI") %>% 
  select(1)

# create a DEI related column
rios_data_tokenizedit$dei_relatedit = NA

# check if the word is DEI related, if so, that row in the 'dei_related' column will be TRUE
rios_data_tokenizedit$dei_relatedit <- sapply(rios_data_tokenizedit$inclusive_teach_tokens, function(x) any(sapply(JEDI_keywords_df, str_detect, string = x)))

# create column that groups based on the shift (2014-2018 and 2019-2022) CHECK AGAIN TO SEE IF YOU STILL NEED THIS IN THIS DF!
rios_data_tokenizedit <- rios_data_tokenizedit %>% #same code as above but different dateframe
  mutate(`Group Year` = case_when(
    as.numeric(Year) <= 2018 ~ "2014 - 2018",
    as.numeric(Year) > 2018 ~ "2019 - 2022"))

# create column of stemmed tokens
rios_data_tokenizedit <- rios_data_tokenizedit %>% 
  mutate(stem = wordStem(rios_data_tokenizedit$inclusive_teach_tokens, language = "en")) %>% 
  rename("inclusive_tokens_stem" = "stem")

```

Below I create a dataframe of the DEI related word counts by year

```{r create wrd ct df}

# save for visuals on word counts, etc
it_word_counts <- rios_data_tokenizedit %>%
  filter(dei_relatedit == "TRUE") %>%
  group_by(Year) %>%
  count(inclusive_teach_tokens, sort = TRUE)

```

# Creating Tokenized Dataframe of 2-word Phrases

I do the same thing I did above, but for *2-word phrases*.

```{r create 2 token df}

# split the text from the `inclusive teaching description` column into a two-token-per-row format
rios_data_token2it <- rios_data %>%
  unnest_tokens(it_tokens_2w, `Inclusive Teaching Description`, token = "ngrams", n = 2)  %>%
  separate(it_tokens_2w, c("word1", "word2"), sep = " ")

# remove ~33,673 rows of english lang. stopwords and then unite the words
rios_data_token2it <- rios_data_token2it %>%
  filter(!word1 %in% stopwords_vec) %>%
  filter(!word2 %in% stopwords_vec) %>% 
  unite(it_tokens_2w, word1, word2, sep = " ") 

# remove ~1,004 rows of punctuation and digits
rios_data_token2it <- rios_data_token2it %>%
  filter(!str_detect(it_tokens_2w, paste(strings, collapse = "|")))

#create a DEI related column
rios_data_token2it$dei_related = NA
```

In the commented code below, I export a CSV of all distinct 2-word phrases in the inclusive teaching section for manual verification again, this time using the verified `JEDI keywords` list (instead of the `dei_keywords` list) and only looking at the phrases labeled as DEI related. After verification, I import it back into R, and create a DEI related colum using this list. 

```{r  deikeywords verification and 2 token df manipulation, warning=FALSE, message=FALSE}

# code to print most common DEI 2word phrases for review

# create a dataframe of all the unique 2-word phrases a.k.a. "tokens" in the inclusive teaching sections
# all2words <- as.data.frame(unique(rios_data_token2it$it_tokens_2w))

# create a column of logical values, if the unique phrases above match any of the JEDI keywords
# all2words$dei_related <- sapply(all2words$`unique(rios_data_token2it$it_tokens_2w)`, function(x) any(sapply(JEDI_keywords, str_detect, string = x)))

# all2words <- all2words %>%
#   filter(dei_related == "TRUE") %>%
#   count(it_tokens_2w, sort = TRUE) 

# export for review
# write_csv(all2words, "2DEIRelated.csv")

# import manually verified list of JEDI 2 word phrases and filter out words that aren't JEDI
JEDI_2keywords_df <- read_csv("https://raw.githubusercontent.com/smsokona/RIOS---CourseSource-Research/master/Data%20Cleaning/Data%20for%20Import/cleanedIT2words.csv") %>% 
  filter(...3 == "JEDI") %>% 
  select(1)

# check if the phrase is DEI related, if so, that row in the 'dei_related' column will be TRUE
rios_data_token2it$dei_related <- sapply(rios_data_token2it$it_tokens_2w, function(x) any(sapply(JEDI_2keywords_df, str_detect, string = x)))

```


# Creating Tokenized Dataframe of 3-word Phrases

I do the same thing I did above, but for *3-word phrases*. Due to time limitations, we don't manually verify the JEDI keyword list for 3-word phrases. Instead, we use the `JEDI_2keyword_df` list imported above.

```{r create 3 token df and manipulate}

# split the text from the `inclusive teaching description` column into a three-token-per-row format
rios_data_token3it <- rios_data %>%
  unnest_tokens(it_tokens_3w, `Inclusive Teaching Description`, token = "ngrams", n = 3)  %>%
  separate(it_tokens_3w, c("word1", "word2", "word3"), sep = " ")

# remove ~41,029 rows of english lang. stopwords and then unite the words
rios_data_token3it <- rios_data_token3it %>%
  filter(!word1 %in% stopwords_vec) %>%
  filter(!word2 %in% stopwords_vec) %>%
  filter(!word3 %in% stopwords_vec) %>%
  unite(it_tokens_3w, word1, word2, word3, sep = " ") 

# remove ~900 rows of punctuation and digits
rios_data_token3it <- rios_data_token3it %>%
  filter(!str_detect(it_tokens_3w, paste(strings, collapse = "|")))

#create a DEI related column
rios_data_token3it$dei_related = NA

# check if the phrase is DEI related, if so, that row in the 'dei_related' column will be TRUE
rios_data_token3it$dei_related <- sapply(rios_data_token3it$it_tokens_3w, function(x) any(sapply(JEDI_2keywords_df, str_detect, string = x)))

```


# Exporting

Below I save all of the cleaned data sets above as a csv in preparation for analysis.

```{r export cleaned dfs}

# original dataframe
write_csv(rios_data, "C:/Users/smangane/OneDrive - bates.edu/RIOS Research/RIOS---CourseSource-Research/Data Cleaning/Data for Export/rios_data.csv") 

# tokenized dataframe
write_csv(rios_data_tokenizedit, "C:/Users/smangane/OneDrive - bates.edu/RIOS Research/RIOS---CourseSource-Research/Data Cleaning/Data for Export/rios_data_tokenized.csv")

# tokenized dataframe for 2word phrases
write_csv(rios_data_token2it, "C:/Users/smangane/OneDrive - bates.edu/RIOS Research/RIOS---CourseSource-Research/Data Cleaning/Data for Export/rios_data_tokenized2.csv")

# tokenized dataframe for 3word phrases
write_csv(rios_data_token3it, "C:/Users/smangane/OneDrive - bates.edu/RIOS Research/RIOS---CourseSource-Research/Data Cleaning/Data for Export/rios_data_tokenized3.csv")

# table of DEI related word counts by year
write_csv(it_word_counts, "C:/Users/smangane/OneDrive - bates.edu/RIOS Research/RIOS---CourseSource-Research/Data Cleaning/Data for Export/dei_word_counts.csv")


# lists of JEDI keywords, just in case
write_csv(JEDI_keywords_df, "C:/Users/smangane/OneDrive - bates.edu/RIOS Research/RIOS---CourseSource-Research/Data Cleaning/Data for Export/JEDIkeywords.csv")
write_csv(JEDI_2keywords_df, "C:/Users/smangane/OneDrive - bates.edu/RIOS Research/RIOS---CourseSource-Research/Data Cleaning/Data for Export/JEDI2keywords.csv")

```


