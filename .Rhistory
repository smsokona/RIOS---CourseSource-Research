filter(dei_relatedit == "TRUE") %>%
group_by(`Group Year`) %>%
summarise(Avg_Wrd_Ct = mean(`Word Count of Inclusive Teaching?`, na.rm = TRUE),
n = n(),
sd = sd(`Word Count of Inclusive Teaching?`, na.rm = TRUE))
rios_data_tokenizedit %>%
filter(dei_relatedit == "TRUE") %>%
group_by(`Group Year`)
rios_data_tokenizedit <- rios_data_tokenizedit %>% #same code as above but different dateframe
mutate(`Group Year` = case_when(
as.numeric(Year) >= 5 ~ "2014 - 2018",
as.numeric(Year) < 5 ~ "2019 - 2022"))
rios_data_tokenizedit %>%
count(`Group Year`)
rios_data <- rios_data %>%
mutate(`Group Year` = case_when(
as.numeric(Year) >= 5 ~ "2014 - 2018",
as.numeric(Year) < 5 ~ "2019 - 2022"
)) #creating column that groups based on the shift (2014-2018 and 2019-2022), used 5 because it's factored and 2018 = level 5
rios_data %>%
count(`Group Year`)
as.numeric(rios_data$Year)
rios_data <- rios_data %>%
mutate(`Group Year` = case_when(
as.numeric(Year) <= 2018 ~ "2014 - 2018",
as.numeric(Year) > 2018 ~ "2019 - 2022"
)) #creating column that groups based on the shift (2014-2018 and 2019-2022), used 5 because it's factored and 2018 = level 5
rios_data %>%
count(`Group Year`)
rios_data_tokenizedit <- rios_data_tokenizedit %>% #same code as above but different dateframe
mutate(`Group Year` = case_when(
as.numeric(Year) <= 2018 ~ "2014 - 2018",
as.numeric(Year) > 2018 ~ "2019 - 2022"))
rios_data_tokenizedit %>%
filter(dei_relatedit == "TRUE") %>%
group_by(`Group Year`) %>%
summarise(Avg_Wrd_Ct = mean(`Word Count of Inclusive Teaching?`, na.rm = TRUE),
n = n(),
sd = sd(`Word Count of Inclusive Teaching?`, na.rm = TRUE))
rios_data_tokenizedit %>%
count(`Attended Workshop?`)
rios_data_tokenizedit %>%
filter(deirelated == "TRUE") %>%
count(`Attended Workshop?`)
rios_data_tokenizedit %>%
filter(rios_data_tokenizedit$dei_relatedit == "TRUE") %>%
count(rios_data_tokenizedit$`Attended Workshop?`)
rios_data_tokenizedit %>% filter(rios_data_tokenizedit$dei_relatedit == "TRUE") %>%
+ count(rios_data_tokenizedit$`Attended Workshop?`)
rios_data_tokenizedit %>% filter(rios_data_tokenizedit$dei_relatedit == "TRUE") %>% count(`Attended Workshop?`)
rios_data_tokenizedit %>%
filter(dei_relatedit == "TRUE") %>%
group_by(`Group Year`, `Attended Workshop?`) %>%
summarise(Avg_Wrd_Ct = mean(`Word Count of Inclusive Teaching?`, na.rm = TRUE),
n = n(),
sd = sd(`Word Count of Inclusive Teaching?`, na.rm = TRUE))
rios_data_tokenizedit %>%
filter(dei_relatedit == "TRUE") %>%
group_by(`Group Year`, `Attended Workshop?`)
rios_data_tokenizedit %>%
filter(dei_relatedit == "TRUE") %>%
group_by(`Group Year`, `Attended Workshop?`) %>%
summarise(total_article = n(article_num))
rios_data_tokenizedit %>%
filter(dei_relatedit == "TRUE") %>%
group_by(`Group Year`, `Attended Workshop?`) %>%
count(inclusive_teach_tokens) %>%
summarise(totaldeia = n())
rios_data_tokenizedit %>%
filter(dei_relatedit == "TRUE") %>%
group_by(`Group Year`, `Attended Workshop?`) %>%
count(article_num) %>%
summarise(totalarticles = n())
rios_data_tokenizedit %>%
filter(`Attended Workshop?` == "Yes" & dei_relatedit == "FALSE")
rios_data %>% filter(`Attended Workshop?` == "Yes" & dei_relatedit == "FALSE")
rios_data_tokenizedit %>% filter(`Attended Workshop?` == "Yes" & dei_relatedit == "FALSE") %>% count(article_num)
rios_data_tokenizedit %>%
group_by(`Group Year`, `Attended Workshop?`) %>% #39 are DEI related and have attended workshops after 2019
filter(`Attended Workshop?` == "Yes" & dei_relatedit == "FALSE") %>%
count(article_num)
rios_data_tokenizedit %>%
group_by(`Group Year`, `Attended Workshop?`, dei_relatedit) %>% #39 are DEI related and have attended workshops after 2019
filter(`Attended Workshop?` == "Yes") %>%
count(article_num)
rios_data %>%
group_by(`Group Year`, `Attended Workshop?`)
rios_data %>%
group_by(`Group Year`, `Attended Workshop?`) %>%
count(`Attended Workshop?`)
rios_data_tokenizedit %>%
group_by(`Group Year`, `Attended Workshop?`, dei_relatedit) %>% #39 are DEI related and have attended workshops after 2019
filter(`Attended Workshop?` == "Yes" & `Group Year` == "2019 - 2022") %>%
count(article_num)
rios_data_tokenizedit %>%
group_by(`Group Year`, `Attended Workshop?`, dei_relatedit) %>% #39 are DEI related and have attended workshops after 2019
filter(`Attended Workshop?` == "No" & `Group Year` == "2019 - 2022") %>%
count(article_num)
rios_data %>%
group_by(`Group Year`, `Attended Workshop?`) %>%
count(`Attended Workshop?`)
rios_data_tokenizedit %>%
filter(dei_relatedit != "TRUE") %>%
group_by(`Group Year`, `Attended Workshop?`) %>%
count(article_num) %>%
summarise(totalarticles = n())
rios_data_tokenizedit %>%
filter(dei_relatedit == "FALSE") %>%
group_by(`Group Year`, `Attended Workshop?`) %>%
count(article_num) %>%
summarise(totalarticles = n())
View(rios_data_tokenizedit)
rios_data %>%
group_by(`Group Year`, `Attended Workshop?`) %>%
count(`Attended Workshop?`)
#totaldei for each year
totaldeiyear <- it_word_counts %>%
summarise(totaldeiy = n())
#total words in each article,
totalwordsarticle <-  rios_data_tokenizedit %>%
group_by(article_num) %>%
count(inclusive_teach_tokens, sort = TRUE)  %>%
summarise(totala = n())
#totaldei for each article, only 251 obs, so some articles don't have any dei related words (30 articles with no Inclusive Teaching Section...)
totaldeiarticle <- rios_data_tokenizedit %>%
filter(dei_relatedit == "TRUE") %>%
group_by(article_num, Year) %>%
count(inclusive_teach_tokens) %>%
summarise(totaldeia = n())
View(totaldeiarticle)
rios_data <- rios_data %>%
filter(`Inclusive Teaching  included?` != "No" | `Inclusive Teaching  included?` != "no")
View(rios_data)
#importing dataset and DEI words list
rios_data <- read_csv("RIOS Research - Course Source - Sheet1 2.csv")
rios_data %>%
count(`Inclusive Teaching  included?`)
#updating human error for one article
rios_data$`Inclusive Teaching  included?`[12] = "No"
rios_data %>%
count(`Inclusive Teaching  included?`)
rios_data <- rios_data %>%
filter(`Inclusive Teaching  included?` != "No")
rios_data <- rios_data %>%
mutate(`Attended Workshop?` = case_when(
rios_data$`Attended Workshop?` == "yes" ~ "Yes", #40 articles
TRUE ~ "No"
))
rios_data <- rios_data %>%
mutate(`Group Year` = case_when(
as.numeric(Year) <= 2018 ~ "2014 - 2018",
as.numeric(Year) > 2018 ~ "2019 - 2022"
)) #creating column that groups based on the shift (2014-2018 and 2019-2022), used 5 because it's factored and 2018 = level 5
rios_data %>%
group_by(`Group Year`, `Attended Workshop?`) %>%
count(`Attended Workshop?`)
#importing dataset and DEI words list
rios_data <- read_csv("RIOS Research - Course Source - Sheet1 2.csv")
rios_data %>%
count(`Article Type?`)
rios_data %>%
group_by(`Inclusive Teaching  included?`) %>%
count(`Article Type?`)
#CREATING A BAR PLOT OF THE AVERAGE WORD COUNT OF THE TWO GROUPS
rios_data <- rios_data %>%
mutate(`Group Year` = case_when(
as.numeric(Year) <= 2018 ~ "2014 - 2018",
as.numeric(Year) > 2018 ~ "2019 - 2022"
)) #creating column that groups based on the shift (2014-2018 and 2019-2022), used 5 because it's factored and 2018 = level 5
rios_data_tokenizedit <- rios_data_tokenizedit %>% #same code as above but different dateframe
mutate(`Group Year` = case_when(
as.numeric(Year) <= 2018 ~ "2014 - 2018",
as.numeric(Year) > 2018 ~ "2019 - 2022"))
# rios_data_tokenizedit %>%
#   filter(dei_relatedit == "TRUE") %>%
#   group_by(`Group Year`, `Attended Workshop?`) %>% #39 are DEI related and have attended workshops after 2019
#   summarise(Avg_Wrd_Ct = mean(`Word Count of Inclusive Teaching?`, na.rm = TRUE),
#             n = n(),
#             sd = sd(`Word Count of Inclusive Teaching?`, na.rm = TRUE))
# rios_data_tokenizedit %>%
#   group_by(`Group Year`, `Attended Workshop?`, dei_relatedit) %>% #39 are DEI related and have attended workshops after 2019
#   filter(`Attended Workshop?` == "No" & `Group Year` == "2019 - 2022") %>%
#   count(article_num)
# test <- t.test(formula = `Word Count of Inclusive Teaching?` ~ `Group Year`,
#          data = rios_data)
#
# test #p-value = 1.557e-10, confidence interval:  -126.37537  -68.78427, df = 254?!
rios_data %>%
group_by(`Group Year`) %>%
summarise(Avg_Wrd_Ct = mean(`Word Count of Inclusive Teaching?`, na.rm = TRUE), #calculating avg wrd count for each group
n = n(),
sd = sd(`Word Count of Inclusive Teaching?`, na.rm = TRUE)) %>% #calculating standard deviation for each group (for confidence intervals) %>%
mutate(se = sd/sqrt(n), #calculating the standard error
ic = se * qt((1-0.05)/2 + 0.5, n-1)) %>% #calculating standard error * value of the t-distribution for 0.5
ggplot(aes(`Group Year`, Avg_Wrd_Ct, fill = `Group Year`)) +
geom_col() +
labs(title = "Average Word Count of Inclusive Teaching Section", subtitle = "Before and After 2018", x = "Year", y = "Average Word Count") +
scale_fill_manual(values = c("#1f78b4", "#b2df8a")) + #manually coloring groups (color blind safe colors)
geom_errorbar(aes(x = `Group Year`, ymin = Avg_Wrd_Ct - ic, ymax = Avg_Wrd_Ct + ic), width = 0.4)
# rios_data_tokenizedit %>%
#     filter(dei_relatedit == "FALSE") %>%
#     group_by(`Group Year`, `Attended Workshop?`) %>%
#     count(article_num) %>%
#     summarise(totalarticles = n())
#facotring years so i can reorder from oldest to most recent
rios_data$Year <- factor(rios_data$Year , levels=c("2022", "2021", "2020", "2019", "2018", "2017", "2016", "2015", "2014"))
#coloring groups (color blind safe colors) based on the shift (2014-2018 and 2019-2022)
boxplot(`Word Count of Inclusive Teaching?`~ Year,
data=rios_data,
main="Word Count of Inclusive Teaching Sections Over Time",
ylab="Year",
xlab="Word count of Inclusive Teaching Section",
horizontal = TRUE,
col = c("#1f78b4", "#1f78b4", "#1f78b4", "#1f78b4", "#b2df8a","#b2df8a", "#b2df8a", "#b2df8a", "#b2df8a"))
abline(v = 118.4868, col = "#b2df8a", lty = "solid", lwd = 3)
abline(v = 216.0667, col = "#1f78b4",lty = "solid", lwd = 3)
legend("topright", inset=.02, title="Average Word Count",
c("for 2014 - 2018","for 2019 - 2022"), fill=c("#b2df8a", "#1f78b4"), horiz=TRUE, cex=0.8)
rios_data$Year <-  unfactor(rios_data$Year)
#1f78b4
#b2df8a
?unnest_tokens
it_stem_word_counts %>%
# filter(Year != 2018) %>%
filter(n > 1) %>% #41.58 of data
ggplot(aes(Year, n, colour = inclusive_tokens_stem)) +
geom_line() +
#geom_text(aes(label = inclusive_teach_tokens), vjust = -0.5, size = 1, nudge_y = 1) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
#facet_wrap(~Year, ncol = 2) +
ylim(0,60) +
labs(title = "(DEI Related) Stemmed Word Frequency Over Time", x = "Year", y = "Word Count in Inclusive Teaching Text") +
## reduce spacing between labels and bars
#scale_x_discrete(expand = c(.01, .01)) +
#scale_fill_identity(guide = "none") +
## get rid of all elements except y axis labels + adjust plot margin +
theme(axis.text.y = element_text(size = 7, hjust = 1, family = "Fira Sans"),
plot.margin = margin(rep(15, 4)))
it_stem_word_counts %>%
# filter(Year != 2018) %>%
filter(n > 1) %>% #41.58 of data
ggplot(aes(Year, n, colour = inclusive_tokens_stem)) +
geom_line(show.legend = FALSE) +
#geom_text(aes(label = inclusive_teach_tokens), vjust = -0.5, size = 1, nudge_y = 1) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
#facet_wrap(~Year, ncol = 2) +
ylim(0,60) +
labs(title = "(DEI Related) Stemmed Word Frequency Over Time", x = "Year", y = "Word Count in Inclusive Teaching Text") +
## reduce spacing between labels and bars
#scale_x_discrete(expand = c(.01, .01)) +
#scale_fill_identity(guide = "none") +
## get rid of all elements except y axis labels + adjust plot margin +
theme(axis.text.y = element_text(size = 7, hjust = 1, family = "Fira Sans"),
plot.margin = margin(rep(15, 4)))
rios_data %>%
group_by(`Attended Workshop?`) %>%
summarise(Avg_Wrd_Ct = mean(`Word Count of Inclusive Teaching?`, na.rm = TRUE), #calculating avg wrd count for each group
n = n(),
sd = sd(`Word Count of Inclusive Teaching?`, na.rm = TRUE))
?tidyverse
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# store string containing all required packages
my_packages <- c('varhandle', 'skimr', 'tidyverse', 'tidytext', 'stopwords', "wordcloud", "reshape2", "ggraph", "kableExtra",'readr', 'dplyr', "igraph","SnowballC")
# store all installed packages
ya_installed <- library()$results[,1]
# check whether required packages are already installed and grab only those that still need installation
need_install<-my_packages[!(my_packages %in% ya_installed)]
# install required packages
lapply(need_install, install.packages, character.only = TRUE)
#similar process as above, but loading the packages
# store all installed packages
ya_loaded <- (.packages())
# check whether required packages are already installed and grab only those that still need installation
need_load<-my_packages[!(my_packages %in% ya_loaded)]
# load required packages
lapply(need_load, require, character.only = TRUE)
# import dataset from excel
rios_data <- read_csv("RIOS Research - Course Source - Sheet1 2.csv")
# dataframe used to check for DEI related words or "tokens" in every article; once checked (see line 132), we exported it and manually reviewed the words and then imported it back into R, as you can see below
dei_keywords <- read_csv("SJEDI_words 2022-12-20 18_03_42.csv")
# import dataset from excel
rios_data <- read_csv("RIOS Research - Course Source - Sheet1 2.csv")
# dataframe used to check for DEI related words or "tokens" in every article; once checked (see line 132), we exported it and manually reviewed the words and then imported it back into R, as you can see below
#dei_keywords <- read_csv("SJEDI_words 2022-12-20 18_03_42.csv")
# import manually verified list of JEDI words
JEDI_keywords_df <- read_csv("cleanedITwords - cleanedITwords.csv")
# filter for JEDI words only, and selected the column of words
JEDI_keywords <- JEDI_keywords_df %>%
filter(Carrie == "JEDI") %>%
select(1)
# import manually verified list of JEDI 2 word phrases
JEDI_2keywords_df <- read_csv("cleanedIT2words.csv")
# filter out words that aren't JEDI
JEDI_2keywords <- JEDI_2keywords_df %>%
filter(...3 == "JEDI") %>%
select(1)
View(JEDI_2keywords_df)
# import dataset from excel
rios_data <- read_csv("RIOS Research - Course Source - Sheet1 2.csv")
# dataframe used to check for DEI related words or "tokens" in every article; once checked (see line 132), we exported it and manually reviewed the words and then imported it back into R, as you can see below
#dei_keywords <- read_csv("SJEDI_words 2022-12-20 18_03_42.csv")
# import manually verified list of JEDI words and filter for JEDI words only
JEDI_keywords_df <- read_csv("cleanedITwords - cleanedITwords.csv") %>%
filter(Carrie == "JEDI") %>%
select(1)
# import manually verified list of JEDI 2 word phrases and filter out words that aren't JEDI
JEDI_2keywords_df <- read_csv("cleanedIT2words.csv") %>%
filter(...3 == "JEDI") %>%
select(1)
View(JEDI_keywords_df)
View(JEDI_2keywords_df)
# fix human error for one article
rios_data$`Inclusive Teaching  included?`[12] = "No"
# remove any article that that doesn't have an inclusive teaching section (30 articles)
rios_data <- rios_data %>%
filter(`Inclusive Teaching  included?` != "No")
# arrange years
rios_data <- rios_data %>%
arrange(desc(Year))
# create a new column which numbers each article (most recent article: 286)
rios_data$article_num <- c(nrow(rios_data):1)
# create column that groups based on the shift (2014-2018 and 2019-2022)
rios_data <- rios_data %>%
mutate(`Group Year` = case_when(
as.numeric(Year) <= 2018 ~ "2014 - 2018",
as.numeric(Year) > 2018 ~ "2019 - 2022"
))
# decapitalize all strings
for (i in 1:length(rios_data$`Inclusive Teaching Description`)) {
rios_data$`Inclusive Teaching Description`[i]<-str_to_lower(rios_data$`Inclusive Teaching Description`[i])
}
# make replacing patterns and replace all
rep_str<-c("alt-text"="alttext", "co-"="co", "re-"="re", "de-"="de", "D/hh"="dhh")
rios_data$`Inclusive Teaching Description`<-str_replace_all(rios_data$`Inclusive Teaching Description`, rep_str)
# remove all
rios_data$`Inclusive Teaching Description`<-str_remove_all(rios_data$`Inclusive Teaching Description`, "et")
# split the text from the `inclusive teaching description` column into a one-token-per-row format
rios_data_tokenizedit <- rios_data %>%
unnest_tokens(output = inclusive_teach_tokens, input = `Inclusive Teaching Description`)
# store unnecessary punctuation, digits, or "stopwords" in a vector for removal (~20k rows total)
strings <- c("[:punct:]", "[:digit:]","\\(","\\)")
stopwords_vec <- stopwords(language = "en")
stopwords_vec <- stopwords_vec[-c(165:167)]
# remove ~777 rows of punctuation and digits
rios_data_tokenizedit <- rios_data_tokenizedit %>%
filter(!str_detect(inclusive_teach_tokens, paste(strings, collapse = "|")))
# remove ~19,663 rows of english lang. stopwords
rios_data_tokenizedit <- rios_data_tokenizedit %>%
filter(!inclusive_teach_tokens %in% stopwords_vec)
# create a DEI related column
rios_data_tokenizedit$dei_relatedit = NA
# check if the word is DEI related, if so, that row in the 'dei_related' column will be TRUE
rios_data_tokenizedit$dei_relatedit <- sapply(rios_data_tokenizedit$inclusive_teach_tokens, function(x) any(sapply(JEDI_keywords_df, str_detect, string = x)))
View(rios_data_tokenizedit)
rios_data %>%
count(rios_data$`Attended Workshop?`)
View(rios_data)
# remove unnecessary columns
rios_data <- rios_data[,-c(11:14)]
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# store string containing all required packages
my_packages <- c('varhandle', 'skimr', 'tidyverse', 'tidytext', 'stopwords', "wordcloud", "reshape2", "ggraph", "kableExtra",'readr', 'dplyr', "igraph","SnowballC")
# store all installed packages
ya_installed <- library()$results[,1]
# check whether required packages are already installed and grab only those that still need installation
need_install<-my_packages[!(my_packages %in% ya_installed)]
# install required packages
lapply(need_install, install.packages, character.only = TRUE)
#similar process as above, but loading the packages
# store all installed packages
ya_loaded <- (.packages())
# check whether required packages are already installed and grab only those that still need installation
need_load<-my_packages[!(my_packages %in% ya_loaded)]
# load required packages
lapply(need_load, require, character.only = TRUE)
# import dataset from excel
rios_data <- read_csv("RIOS Research - Course Source - Sheet1 2.csv")
# dataframe used to check for DEI related words or "tokens" in every article; once checked (see line 132), we exported it and manually reviewed the words and then imported it back into R, as you can see below
#dei_keywords <- read_csv("SJEDI_words 2022-12-20 18_03_42.csv")
# import manually verified list of JEDI words and filter for JEDI words only
JEDI_keywords_df <- read_csv("cleanedITwords - cleanedITwords.csv") %>%
filter(Carrie == "JEDI") %>%
select(1)
# import manually verified list of JEDI 2 word phrases and filter out words that aren't JEDI
JEDI_2keywords_df <- read_csv("cleanedIT2words.csv") %>%
filter(...3 == "JEDI") %>%
select(1)
View(rios_data)
# fix human error for one article
rios_data$`Inclusive Teaching  included?`[12] = "No"
# remove any article that that doesn't have an inclusive teaching section (30 articles)
rios_data <- rios_data %>%
filter(`Inclusive Teaching  included?` != "No")
# arrange years
rios_data <- rios_data %>%
arrange(desc(Year))
# create a new column which numbers each article (most recent article: 286)
rios_data$article_num <- c(nrow(rios_data):1)
# create column that groups based on the shift (2014-2018 and 2019-2022)
rios_data <- rios_data %>%
mutate(`Group Year` = case_when(
as.numeric(Year) <= 2018 ~ "2014 - 2018",
as.numeric(Year) > 2018 ~ "2019 - 2022"
))
# remove unnecessary columns
rios_data <- rios_data[,-c(11:14)]
# decapitalize all strings
for (i in 1:length(rios_data$`Inclusive Teaching Description`)) {
rios_data$`Inclusive Teaching Description`[i]<-str_to_lower(rios_data$`Inclusive Teaching Description`[i])
}
# make replacing patterns and replace all
rep_str<-c("alt-text"="alttext", "co-"="co", "re-"="re", "de-"="de", "D/hh"="dhh")
rios_data$`Inclusive Teaching Description`<-str_replace_all(rios_data$`Inclusive Teaching Description`, rep_str)
# remove all
rios_data$`Inclusive Teaching Description`<-str_remove_all(rios_data$`Inclusive Teaching Description`, "et")
# split the text from the `inclusive teaching description` column into a one-token-per-row format
rios_data_tokenizedit <- rios_data %>%
unnest_tokens(output = inclusive_teach_tokens, input = `Inclusive Teaching Description`)
# store unnecessary punctuation, digits, or "stopwords" in a vector for removal (~20k rows total)
strings <- c("[:punct:]", "[:digit:]","\\(","\\)")
stopwords_vec <- stopwords(language = "en")
stopwords_vec <- stopwords_vec[-c(165:167)]
# remove ~747 rows of punctuation and digits
rios_data_tokenizedit <- rios_data_tokenizedit %>%
filter(!str_detect(inclusive_teach_tokens, paste(strings, collapse = "|")))
# remove ~19,470 rows of english lang. stopwords
rios_data_tokenizedit <- rios_data_tokenizedit %>%
filter(!inclusive_teach_tokens %in% stopwords_vec)
# create a DEI related column
rios_data_tokenizedit$dei_relatedit = NA
# check if the word is DEI related, if so, that row in the 'dei_related' column will be TRUE
rios_data_tokenizedit$dei_relatedit <- sapply(rios_data_tokenizedit$inclusive_teach_tokens, function(x) any(sapply(JEDI_keywords_df, str_detect, string = x)))
# create column that groups based on the shift (2014-2018 and 2019-2022) CHECK AGAIN TO SEE IF YOU STILL NEED THIS IN THIS DF!
rios_data_tokenizedit <- rios_data_tokenizedit %>% #same code as above but different dateframe
mutate(`Group Year` = case_when(
as.numeric(Year) <= 2018 ~ "2014 - 2018",
as.numeric(Year) > 2018 ~ "2019 - 2022"))
# create column of stemmed tokens
rios_data_tokenizedit <- rios_data_tokenizedit %>%
mutate(stem = wordStem(rios_data_tokenizedit$inclusive_teach_tokens, language = "en")) %>%
rename("inclusive_tokens_stem" = "stem")
View(rios_data_tokenizedit)
# save for visuals on word counts, etc
it_word_counts <- rios_data_tokenizedit %>%
filter(dei_relatedit == "TRUE") %>%
group_by(Year) %>%
count(inclusive_teach_tokens, sort = TRUE)
# split the text from the `inclusive teaching description` column into a two-token-per-row format
rios_data_token2it <- rios_data %>%
unnest_tokens(it_tokens_2w, `Inclusive Teaching Description`, token = "ngrams", n = 2)  %>%
separate(it_tokens_2w, c("word1", "word2"), sep = " ")
# remove SAY NUMBER rows of english lang. stopwords and then unite the words
rios_data_token2it <- rios_data_token2it %>%
filter(!word1 %in% stopwords_vec) %>%
filter(!word2 %in% stopwords_vec) %>%
unite(it_tokens_2w, word1, word2, sep = " ")
# remove SAY NUMBER rows of punctuation and digits
rios_data_token2it <- rios_data_token2it %>%
filter(!str_detect(it_tokens_2w, paste(strings, collapse = "|")))
#create a DEI related column
rios_data_token2it$dei_related = NA
# check if the phrase is DEI related, if so, that row in the 'dei_related' column will be TRUE
rios_data_token2it$dei_related <- sapply(rios_data_token2it$it_tokens_2w, function(x) any(sapply(JEDI_2keywords_df, str_detect, string = x)))
# split the text from the `inclusive teaching description` column into a two-token-per-row format
rios_data_token2it <- rios_data %>%
unnest_tokens(it_tokens_2w, `Inclusive Teaching Description`, token = "ngrams", n = 2)  %>%
separate(it_tokens_2w, c("word1", "word2"), sep = " ")
# remove SAY NUMBER rows of english lang. stopwords and then unite the words
rios_data_token2it <- rios_data_token2it %>%
filter(!word1 %in% stopwords_vec) %>%
filter(!word2 %in% stopwords_vec) %>%
unite(it_tokens_2w, word1, word2, sep = " ")
# remove SAY NUMBER rows of punctuation and digits
rios_data_token2it <- rios_data_token2it %>%
filter(!str_detect(it_tokens_2w, paste(strings, collapse = "|")))
#create a DEI related column
rios_data_token2it$dei_related = NA
# check if the phrase is DEI related, if so, that row in the 'dei_related' column will be TRUE
rios_data_token2it$dei_related <- sapply(rios_data_token2it$it_tokens_2w, function(x) any(sapply(JEDI_2keywords_df, str_detect, string = x)))
# split the text from the `inclusive teaching description` column into a three-token-per-row format
rios_data_token3it <- rios_data %>%
unnest_tokens(it_tokens_3w, `Inclusive Teaching Description`, token = "ngrams", n = 3)  %>%
separate(it_tokens_3w, c("word1", "word2", "word3"), sep = " ")
# remove SAY NUMBER rows of english lang. stopwords and then unite the words
rios_data_token3it <- rios_data_token3it %>%
filter(!word1 %in% stopwords_vec) %>%
filter(!word2 %in% stopwords_vec) %>%
filter(!word3 %in% stopwords_vec) %>%
unite(it_tokens_3w, word1, word2, word3, sep = " ")
# remove SAY NUMBER rows of punctuation and digits
rios_data_token3it <- rios_data_token3it %>%
filter(!str_detect(it_tokens_3w, paste(strings, collapse = "|")))
#create a DEI related column
rios_data_token3it$dei_related = NA
# check if the phrase is DEI related, if so, that row in the 'dei_related' column will be TRUE
rios_data_token3it$dei_related <- sapply(rios_data_token3it$it_tokens_3w, function(x) any(sapply(dei_keywords, str_detect, string = x)))
# check if the phrase is DEI related, if so, that row in the 'dei_related' column will be TRUE
rios_data_token3it$dei_related <- sapply(rios_data_token3it$it_tokens_3w, function(x) any(sapply(JEDI_2keywords_df, str_detect, string = x)))
# original dataframe
write_csv2(rios_data, "rios_data.csv")
# tokenized dataframe
write_csv2(rios_data_tokenizedit, "rios_data_tokenized.csv")
# tokenized dataframe for 2word phrases
write_csv2(rios_data_token2it, "rios_data_tokenized2.csv")
# tokenized dataframe for 3word phrases
write_csv2(rios_data_token3it, "rios_data_tokenized3.csv")
# table of DEI related word counts by year
write_csv2(it_word_counts, "dei_word_counts.csv")
# list of JEDI keywords list, just in case
write_csv2(JEDI_keywords_df, "JEDIkeywords.csv")
write_csv2(JEDI_2keywords_df, "JEDI2keywords.csv")
