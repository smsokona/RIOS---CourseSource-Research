strings <- c("[:punct:]", "[:digit:]","\\(","\\)")
stopwords_vec <- stopwords(language = "en")
stopwords_vec <- stopwords_vec[-c(165:167)]
#removed ~777 rows
rios_data_tokenizedit <- rios_data_tokenizedit %>%
filter(!str_detect(inclusive_teach_tokens, paste(strings, collapse = "|")))
#removed ~19,663 rows
rios_data_tokenizedit <- rios_data_tokenizedit %>%
filter(!inclusive_teach_tokens %in% stopwords_vec)
#importing manually verified list of JEDI words
JEDI_keywords_df <- read_csv("cleanedITwords - cleanedITwords.csv")
JEDI_keywords <- JEDI_keywords_df %>%
filter(Carrie == "JEDI") %>%
select(1)
View(JEDI_keywords)
#creating a DEI related column
rios_data_tokenizedit$dei_relatedit = NA
rios_data_tokenizedit$dei_relatedit <- sapply(rios_data_tokenizedit$inclusive_teach_tokens, function(x) any(sapply(JEDI_keywords, str_detect, string = x)))
View(rios_data_tokenizedit)
#removing the unnnecessary columns
rios_data_tokenizedit <- rios_data_tokenizedit[,-c(9:13)]
rios_data$Year <- factor(rios_data$Year , levels=c("2022", "2021", "2020", "2019", "2018", "2017", "2016", "2015", "2014"))
boxplot(`Word Count of Inclusive Teaching?`~ Year,
data=rios_data,
main="Word Count of Inclusive Teaching Sections Over Time",
ylab="Year",
xlab="Word count of Inclusive Teaching Section",
horizontal = TRUE)
rios_data$Year <-  unfactor(rios_data$Year)
rios_data %>%
group_by(Year) %>%
skim(starts_with("Word Count")) %>%
select(3,4,6:13)  %>%
mutate(numeric.mean = round(numeric.mean, digits = 2), numeric.sd = round(numeric.sd, digits = 2)) %>%
rename("Mean" = "numeric.mean",
"SD" = "numeric.sd",
"Min" = "numeric.p0",
"25 Q" = "numeric.p25",
"Median" = "numeric.p50",
"75 Q" = "numeric.p75",
"Max" = "numeric.p100",
"Histogram" = "numeric.hist") %>%
kable() %>%
kable_minimal()
#most common DEI words, out of 118 (out of 4,464 words, 2.6% are DEI)
rios_data_tokenizedit %>%
filter(dei_relatedit == "TRUE") %>%
count(inclusive_teach_tokens, sort = TRUE)
rios_data_tokenizedit %>%
filter(dei_relatedit == "TRUE") %>%
count(inclusive_teach_tokens, sort = TRUE) %>%
with(wordcloud(inclusive_teach_tokens, n))
rios_data_token2it <- rios_data %>%
unnest_tokens(it_tokens_2w, `Inclusive Teaching Description`, token = "ngrams", n = 2)  %>%
separate(it_tokens_2w, c("word1", "word2"), sep = " ")
rios_data_token2it <- rios_data_token2it %>%
filter(!word1 %in% stopwords_vec) %>%
filter(!word2 %in% stopwords_vec) %>%
unite(it_tokens_2w, word1, word2, sep = " ")
rios_data_token2it <- rios_data_token2it %>%
filter(!str_detect(it_tokens_2w, paste(strings, collapse = "|")))
#creating a DEI related column
rios_data_token2it$dei_related = NA
rios_data_token2it$dei_related <- sapply(rios_data_token2it$it_tokens_2w, function(x) any(sapply(JEDI_keywords, str_detect, string = x)))
View(rios_data_token2it)
rios_data_token2it <- rios_data_token2it[,-c(9:13)]
View(rios_data_token2it)
all2words <- unique(rios_data_token2it$it_tokens_2w)
as.data.frame(all2words)
all2words <- as.data.frame(unique(rios_data_token2it$it_tokens_2w))
View(all2words)
View(JEDI_keywords)
View(JEDI_keywords)
all2words[2:]
all2words[2,]
str_detect(allwords[2,], "students")
str_detect(all2words[2,], "students")
str_detect(all2words[3,], "students")
str_detect(all2words[4,], "students")
str_detect(all2words[5,], "students")
unique2deirelated <- sapply(all2words, function(x) any(sapply(JEDI_keywords, str_detect, string = x)))
all2words$dei_related = NA
all2words$dei_related <- sapply(all2words$`unique(rios_data_token2it$it_tokens_2w)`, function(x) any(sapply(JEDI_keywords, str_detect, string = x)))
View(all2words)
write_csv(all2words, "2DEIRelated.csv")
unnecessary <- c("individually table", "individual investigators", "individual module", "individual noninteractive", "individual pre", "individual clicker", "inclusion another", "inclusion additionally", "identify species", "identify primer", "identify possible", "identified alternatively", "identification", "ideas individual", "group divide", "general inclusive", "bird identification", "yet inclusive", "variants identified", "teachers identify", "skills perspectives", "sheet individually", "residential birds", "radiation incidents", "regular individually", "pipeline cure", "plant communities", "popular culture", "perspective remind", "perspectives anonymous", "four individuals", "first collaborative", "find identify", "ever identified", "evenly divides", "ethnic economic", "ethnic given", "equity public", "england individual", "engaging final", "diverse face", "diverse natural", "diverse mixed", "direct connection", "disabilities benefit", "data individuals", "data individually", "communities due", "collaborative yet", "collaborative easing", "collaboration using", "collaboration throughout", "class individual", "biodiversiy lab", "biodiversity losses", "backgrounds may", "backgrounds find", "backgrounds furthermore", "backgrounds therefore", "area identified", "answer individually", "agricultural sciences", "ability train", "ability moreover", "abilities match", "questions individually", "individuals turn", "individuals since", "communicate collaborate", "backgrounds throughout", "access see", "de identified", "efficacy identity", "individualactors may")
rios_data_token2it <- rios_data_token2it %>%
filter(!str_detect(it_tokens_2w, paste(unnecessary, collapse = "|")))
all2words <- as.data.frame(unique(rios_data_token2it$it_tokens_2w))
all2words$dei_related = NA
all2words$dei_related <- sapply(all2words$`unique(rios_data_token2it$it_tokens_2w)`, function(x) any(sapply(JEDI_keywords, str_detect, string = x)))
write_csv(all2words, "2DEIRelated.csv")
## plot the frequency
rios_data_token3it <- rios_data %>%
unnest_tokens(it_tokens_3w, `Inclusive Teaching Description`, token = "ngrams", n = 3)  %>%
separate(it_tokens_3w, c("word1", "word2", "word3"), sep = " ")
rios_data_token3it <- rios_data_token3it %>%
filter(!word1 %in% stopwords_vec) %>%
filter(!word2 %in% stopwords_vec) %>%
filter(!word3 %in% stopwords_vec) %>%
unite(it_tokens_3w, word1, word2, word3, sep = " ")
rios_data_token3it <- rios_data_token3it %>%
filter(!str_detect(it_tokens_3w, paste(strings, collapse = "|")))
#creating a DEI related column
rios_data_token3it$dei_related = NA
rios_data_token3it$dei_related <- sapply(rios_data_token3it$it_tokens_3w, function(x) any(sapply(dei_keywords, str_detect, string = x)))
#removing the unnnecessary columns/rows
rios_data_token3it <- rios_data_token3it[,-c(9:13)]
unnecessary2 <- c("academic background identity", "academic professional backgrounds", "individuals since questions", "inclusive teaching requires", "implements inclusive teaching", "many individuals since", "must communicate collaborate", "several inclusive teaching", "abilities experimental questions", "access discussion throughout", "access faculty access", "access sample work", "access see comments", "access several learning", "access software programs", "access species database", "accommodators perceived individual", "animal communities due", "american cultures science", "author backgrounds demonstrating", "background knowledge differently", "background therefore inexpensive", "backgrounds can benefit", "backgrounds find intellectual", "backgrounds may identify", "backgrounds needs learning", "backgrounds often find", "biodiversity database schools", "biodiversity lab report", "biodiversity losses amount", "biology species identified", "bird identification resources", "broader area identified", "butterfly activity engages", "campus based access", "class individual research", "class collaboration peer", "class individual research", "clicker questions individually", "coast students connected", "collaborative effort seeks", "completed courses backgrounds", "completing individual work", "connected device instructors", "connections may result", "contribute individual data", "cultured bacteria including", "cures increase access", "current biodiversity losses", "cyverse infrastructure connected", "de identified results", "different communities may", "disabilities additionally scientific", "discussing cellular diversity", "diverse demonstrators finally", "diversity among streptomyces", "diversity dna sequence", "diversity gap additionally", "divides labor among", "drift engaging students", "dynamics inclusive learning", "engagement student appropriate", "engages multiple senses", "engaging final presentation", "engaging multiple types", "engaging multiple week", "england individual investigators", "evenly divides labor", "friendly internet connected", "genetic drift engaging", "handle cultured samples", "handling cultured bacteria", "high impact active", "ideas individual writing", "identified asset maps", "identified instructors implementing", "identified personality types", "identify possible therapeutic", "identify primer binding", "inclusion another way", "inclusion standards can", "inclusion within many", "individual choice udl", "individual clicker questions", "individual self paced", "individual pre class", "individual submissions upon", "individual writing assignments", "ndividual writing peer", "individual written report", "individually completing separate", "individually first although", "individually group work", "individually providing time", "individually select groups", "individually selected research", "individuals students work", "instructor individual exploration", "instructor individual pre", "interesting biological cultural", "internet connected device", "investigate genetic diversity", "loxp lesson inclusive", "microorganisms impact human", "might impact human", "natural abilities match", "nuclear radiation incidents", "online bird identification", "open access species", "perspectives anonymous clicker", "plant communities useful", "plant identification http", "practice sheet individually", "prefer individual work", "project biodiversify website", "public biodiversity database", "purposes open access", "pursuing bird identification", "questions individual students", "questions individually discuss", "regular individually selected", "reliable internet connectivity", "revealing identifying information", "rgs encourage individual", "seafood traceability issues", "self identified asset", "self identified personality", "serpentine plant communities", "sheet individually providing", "significantly less connected", "simple model collaboration",	"site easily accessible", "spatial ability train",
"species identified alternatively",	"species identified instructors", "strategies including individual", "traceability issues overall", "videos students engage", "ways first collaborative", "ways individual clicker", "ways individual self", "whether current biodiversity")
rios_data_token3it <- rios_data_token3it %>%
filter(!str_detect(it_tokens_3w, paste(unnecessary2, collapse = "|")))
#for review (Naz?)
all3words <- as.data.frame(unique(rios_data_token3it$it_tokens_3w))
all3words$dei_related = NA
all3words$dei_related <- sapply(all3words$`unique(rios_data_token3it$it_tokens_3w)`, function(x) any(sapply(JEDI_keywords, str_detect, string = x)))
write_csv(all3words, "3DEIRelated.csv")
#saving for visuals on word counts, etc
it_word_counts <- rios_data_tokenizedit %>%
filter(dei_relatedit == "TRUE") %>%
group_by(Year) %>%
count(inclusive_teach_tokens, sort = TRUE)
View(it_word_counts)
it_word_counts %>%
# filter(Year != 2018) %>%
filter(n > 1) %>% #41.58 of data
ggplot(aes(inclusive_teach_tokens, n)) +
geom_col() +
#geom_text(aes(label = inclusive_teach_tokens), vjust = -0.5, size = 1, nudge_y = 1) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
facet_wrap(~Year, ncol = 2) +
ylim(0,33) +
labs(title = "(DEI Related) Word Frequency Over Time", x = "(DEI Related) Word", y = "Word Count in Inclusive Teaching Text") +
## reduce spacing between labels and bars
scale_x_discrete(expand = c(.01, .01)) +
scale_fill_identity(guide = "none") +
## get rid of all elements except y axis labels + adjust plot margin +
theme(axis.text.y = element_text(size = 14, hjust = 1, family = "Fira Sans"),
plot.margin = margin(rep(15, 4)))
it_word_counts %>%
ungroup(Year) %>%
count(n) %>%
mutate(percent = (nn/416)*100)
it_word_counts %>%
ungroup(Year) %>%
count(n)
it_word_counts %>%
filter(Year == 2014) %>%
head(20) %>%
ggplot(aes(inclusive_teach_tokens, n)) +
geom_bar(stat = "identity", show.legend = FALSE) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
ylim(0,33)
it_word_counts %>%
filter(Year == 2015) %>%
head(20) %>%
ggplot(aes(inclusive_teach_tokens, n)) +
geom_bar(stat = "identity", show.legend = FALSE) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
ylim(0,33)
it_word_counts %>%
filter(Year == 2016) %>%
head(20) %>%
ggplot(aes(inclusive_teach_tokens, n)) +
geom_bar(stat = "identity", show.legend = FALSE) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
ylim(0,33)
it_word_counts %>%
filter(Year == 2017) %>%
head(20) %>%
ggplot(aes(inclusive_teach_tokens, n)) +
geom_bar(stat = "identity", show.legend = FALSE) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
ylim(0,33)
it_word_counts %>%
filter(Year == 2018) %>%
head(20) %>%
ggplot(aes(inclusive_teach_tokens, n)) +
geom_bar(stat = "identity", show.legend = FALSE) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
ylim(0,33)
it_word_counts %>%
filter(Year == 2019) %>%
head(20) %>%
ggplot(aes(inclusive_teach_tokens, n)) +
geom_bar(stat = "identity", show.legend = FALSE) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
ylim(0,33)
it_word_counts %>%
filter(Year == 2020) %>%
head(20) %>%
ggplot(aes(inclusive_teach_tokens, n)) +
geom_bar(stat = "identity", show.legend = FALSE) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
ylim(0,33)
it_word_counts %>%
filter(Year == 2021) %>%
head(20) %>%
ggplot(aes(inclusive_teach_tokens, n)) +
geom_bar(stat = "identity", show.legend = FALSE) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
ylim(0,33)
it_word_counts %>%
filter(Year == 2022) %>%
head(20) %>%
ggplot(aes(inclusive_teach_tokens, n)) +
geom_bar(stat = "identity", show.legend = FALSE) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
ylim(0,33)
#finding the most distinctive words for each document
it_word_counts %>%
bind_tf_idf(inclusive_teach_tokens, Year, n) %>%
arrange(desc(tf_idf)) %>%
filter(Year == 2014) %>%
top_n(40) %>%
mutate(it_tokens_3w = reorder(inclusive_teach_tokens,tf_idf)) %>%
ggplot(aes(inclusive_teach_tokens, tf_idf)) +
geom_bar(stat = "identity", show.legend = FALSE) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
labs(title = "(DEI Related) Normalized Word Frequency in Inclusive Teaching Text in 2014", x = "DEI Related Words", y = "Word Weight (tf-idf statistic") + ylim(0,0.095)
it_word_counts %>%
bind_tf_idf(inclusive_teach_tokens, Year, n) %>%
arrange(desc(tf_idf)) %>%
filter(Year == 2015) %>%
top_n(30) %>%
mutate(it_tokens_3w = reorder(inclusive_teach_tokens,tf_idf)) %>%
ggplot(aes(inclusive_teach_tokens, tf_idf)) +
geom_bar(stat = "identity", show.legend = FALSE) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
labs(title = "(DEI Related) Normalized Word Frequency in Inclusive Teaching Text in 2015", x = "DEI Related Words", y = "Word Weight (tf-idf statistic") + ylim(0,0.095)
it_word_counts %>%
bind_tf_idf(inclusive_teach_tokens, Year, n) %>%
arrange(desc(tf_idf)) %>%
filter(Year == 2016) %>%
top_n(30) %>%
mutate(it_tokens_3w = reorder(inclusive_teach_tokens,tf_idf)) %>%
ggplot(aes(inclusive_teach_tokens, tf_idf)) +
geom_bar(stat = "identity", show.legend = FALSE) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
labs(title = "(DEI Related) Normalized Word Frequency in Inclusive Teaching Text in 2016", x = "DEI Related Words", y = "Word Weight (tf-idf statistic") + ylim(0,0.095)
it_word_counts %>%
bind_tf_idf(inclusive_teach_tokens, Year, n) %>%
arrange(desc(tf_idf)) %>%
filter(Year == 2017) %>%
top_n(30) %>%
mutate(it_tokens_3w = reorder(inclusive_teach_tokens,tf_idf)) %>%
ggplot(aes(inclusive_teach_tokens, tf_idf)) +
geom_bar(stat = "identity", show.legend = FALSE) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
labs(title = "(DEI Related) Normalized Word Frequency in Inclusive Teaching Text in 2017", x = "DEI Related Words", y = "Word Weight (tf-idf statistic") + ylim(0,0.095)
it_word_counts %>%
bind_tf_idf(inclusive_teach_tokens, Year, n) %>%
arrange(desc(tf_idf)) %>%
filter(Year == 2018) %>%
top_n(30) %>%
mutate(it_tokens_3w = reorder(inclusive_teach_tokens,tf_idf)) %>%
ggplot(aes(inclusive_teach_tokens, tf_idf)) +
geom_bar(stat = "identity", show.legend = FALSE) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
labs(title = "(DEI Related) Normalized Word Frequency in Inclusive Teaching Text in 2018", x = "DEI Related Words", y = "Word Weight (tf-idf statistic") + ylim(0,0.095)
it_word_counts %>%
bind_tf_idf(inclusive_teach_tokens, Year, n) %>%
arrange(desc(tf_idf)) %>%
filter(Year == 2019) %>%
top_n(30) %>%
mutate(it_tokens_3w = reorder(inclusive_teach_tokens,tf_idf)) %>%
ggplot(aes(inclusive_teach_tokens, tf_idf)) +
geom_bar(stat = "identity", show.legend = FALSE) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
labs(title = "(DEI Related) Normalized Word Frequency in Inclusive Teaching Text in 2019", x = "DEI Related Words", y = "Word Weight (tf-idf statistic") + ylim(0,0.095)
it_word_counts %>%
bind_tf_idf(inclusive_teach_tokens, Year, n) %>%
arrange(desc(tf_idf)) %>%
filter(Year == 2020) %>%
top_n(30) %>%
mutate(it_tokens_3w = reorder(inclusive_teach_tokens,tf_idf)) %>%
ggplot(aes(inclusive_teach_tokens, tf_idf)) +
geom_bar(stat = "identity", show.legend = FALSE) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
labs(title = "(DEI Related) Normalized Word Frequency in Inclusive Teaching Text in 2020", x = "DEI Related Words", y = "Word Weight (tf-idf statistic") + ylim(0,0.095)
it_word_counts %>%
bind_tf_idf(inclusive_teach_tokens, Year, n) %>%
arrange(desc(tf_idf)) %>%
filter(Year == 2021) %>%
top_n(30) %>%
mutate(it_tokens_3w = reorder(inclusive_teach_tokens,tf_idf)) %>%
ggplot(aes(inclusive_teach_tokens, tf_idf)) +
geom_bar(stat = "identity", show.legend = FALSE) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
labs(title = "(DEI Related) Normalized Word Frequency in Inclusive Teaching Text in 2021", x = "DEI Related Words", y = "Word Weight (tf-idf statistic") + ylim(0,0.095)
it_word_counts %>%
bind_tf_idf(inclusive_teach_tokens, Year, n) %>%
arrange(desc(tf_idf)) %>%
filter(Year == 2022) %>%
top_n(30) %>%
mutate(it_tokens_3w = reorder(inclusive_teach_tokens,tf_idf)) %>%
ggplot(aes(inclusive_teach_tokens, tf_idf)) +
geom_bar(stat = "identity", show.legend = FALSE) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
labs(title = "(DEI Related) Normalized Word Frequency in Inclusive Teaching Text in 2022", x = "DEI Related Words", y = "Word Weight (tf-idf statistic)") + ylim(0,0.095)
rios_data_token2 <- rios_data_token2it %>%
separate(it_tokens_2w, c("word1", "word2"), sep = " ")
rios_phrase_network <- rios_data_token2 %>%
filter(dei_related == TRUE & Year == 2014) %>%
count(word1, word2, sort = TRUE) %>%
graph_from_data_frame()
set.seed(20181005)
a <- arrow(angle = 30, length = unit(0.1, "inches"), ends = "last", type = "open")
ggraph(rios_phrase_network, layout = "fr") + geom_edge_link(aes(color = n, width = n), arrow = a) +
geom_node_point() + geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
labs(title = "Network Plot of (DEI Related) Word Relationship in 2014")
rios_data_token2 <- rios_data_token2it %>%
separate(it_tokens_2w, c("word1", "word2"), sep = " ")
rios_phrase_network <- rios_data_token2 %>%
filter(dei_related == TRUE & Year == 2015) %>%
count(word1, word2, sort = TRUE) %>%
graph_from_data_frame()
set.seed(20181005)
a <- arrow(angle = 30, length = unit(0.1, "inches"), ends = "last", type = "open")
ggraph(rios_phrase_network, layout = "fr") + geom_edge_link(aes(color = n, width = n), arrow = a) +
geom_node_point() + geom_node_text(aes(label = name), vjust = 1, hjust = 1)
rios_data_token2 <- rios_data_token2it %>%
separate(it_tokens_2w, c("word1", "word2"), sep = " ")
rios_phrase_network <- rios_data_token2 %>%
filter(dei_related == TRUE & Year == 2016) %>%
count(word1, word2, sort = TRUE) %>%
graph_from_data_frame()
set.seed(20181005)
a <- arrow(angle = 30, length = unit(0.1, "inches"), ends = "last", type = "open")
ggraph(rios_phrase_network, layout = "fr") + geom_edge_link(aes(color = n, width = n), arrow = a) +
geom_node_point() + geom_node_text(aes(label = name), vjust = 1, hjust = 1)
rios_data_token2 <- rios_data_token2it %>%
separate(it_tokens_2w, c("word1", "word2"), sep = " ")
rios_phrase_network <- rios_data_token2 %>%
filter(dei_related == TRUE & Year == 2017) %>%
count(word1, word2, sort = TRUE) %>%
graph_from_data_frame()
set.seed(20181005)
a <- arrow(angle = 30, length = unit(0.1, "inches"), ends = "last", type = "open")
ggraph(rios_phrase_network, layout = "fr") + geom_edge_link(aes(color = n, width = n), arrow = a) +
geom_node_point() + geom_node_text(aes(label = name), vjust = 1, hjust = 1)
rios_data_token2 <- rios_data_token2it %>%
separate(it_tokens_2w, c("word1", "word2"), sep = " ")
rios_phrase_network <- rios_data_token2 %>%
filter(dei_related == TRUE & Year == 2018) %>%
count(word1, word2, sort = TRUE) %>%
graph_from_data_frame()
set.seed(20181005)
a <- arrow(angle = 30, length = unit(0.1, "inches"), ends = "last", type = "open")
ggraph(rios_phrase_network, layout = "fr") + geom_edge_link(aes(color = n, width = n), arrow = a) +
geom_node_point() + geom_node_text(aes(label = name), vjust = 1, hjust = 1)
rios_data_token2 <- rios_data_token2it %>%
separate(it_tokens_2w, c("word1", "word2"), sep = " ")
rios_phrase_network <- rios_data_token2 %>%
filter(dei_related == TRUE & Year == 2019) %>%
count(word1, word2, sort = TRUE) %>%
graph_from_data_frame()
set.seed(20181005)
a <- arrow(angle = 30, length = unit(0.1, "inches"), ends = "last", type = "open")
ggraph(rios_phrase_network, layout = "fr") + geom_edge_link(aes(color = n, width = n), arrow = a) +
geom_node_point() + geom_node_text(aes(label = name), vjust = 1, hjust = 1)
rios_data_token2 <- rios_data_token2it %>%
separate(it_tokens_2w, c("word1", "word2"), sep = " ")
rios_phrase_network <- rios_data_token2 %>%
filter(dei_related == TRUE & Year == 2020) %>%
count(word1, word2, sort = TRUE) %>%
graph_from_data_frame()
set.seed(20181005)
a <- arrow(angle = 30, length = unit(0.1, "inches"), ends = "last", type = "open")
ggraph(rios_phrase_network, layout = "fr") + geom_edge_link(aes(color = n, width = n), arrow = a) +
geom_node_point() + geom_node_text(aes(label = name), vjust = 1, hjust = 1)
rios_data_token2 <- rios_data_token2it %>%
separate(it_tokens_2w, c("word1", "word2"), sep = " ")
rios_phrase_network <- rios_data_token2 %>%
filter(dei_related == TRUE & Year == 2021) %>%
count(word1, word2, sort = TRUE) %>%
graph_from_data_frame()
set.seed(20181005)
a <- arrow(angle = 30, length = unit(0.1, "inches"), ends = "last", type = "open")
ggraph(rios_phrase_network, layout = "fr") + geom_edge_link(aes(color = n, width = n), arrow = a) +
geom_node_point() + geom_node_text(aes(label = name), vjust = 1, hjust = 1)
View(dei_keywords)
rios_data_token2 <- rios_data_token2it %>%
separate(it_tokens_2w, c("word1", "word2"), sep = " ")
rios_phrase_network <- rios_data_token2 %>%
filter(dei_related == TRUE & Year == 2022) %>%
count(word1, word2, sort = TRUE) %>%
graph_from_data_frame()
set.seed(20181005)
a <- arrow(angle = 30, length = unit(0.1, "inches"), ends = "last", type = "open")
ggraph(rios_phrase_network, layout = "fr") + geom_edge_link(aes(color = n, width = n), arrow = a) +
geom_node_point() + geom_node_text(aes(label = name), vjust = 1, hjust = 1)  +
labs(title = "Network Plot of (DEI Related) Word Relationship in 2022")
#totaldei for each year
totaldeiyear <- it_word_counts %>%
summarise(totaldeiy = n())
#totaldei for each article, only 251 obs, so some articles don't have any dei related words (30 articles with no Inclusive Teaching Section...)
totaldeiarticle <- rios_data_tokenizedit %>%
filter(dei_relatedit == "TRUE") %>%
group_by(article_num, Year) %>%
count(inclusive_teach_tokens) %>%
summarise(totaldeia = n())
#total words in each year
totalwordsyear <- rios_data_tokenizedit %>%
group_by(Year) %>%
count(inclusive_teach_tokens, sort = TRUE)  %>%
summarise(totaly = n())
#total words in each article,
totalwordsarticle <-  rios_data_tokenizedit %>%
group_by(article_num) %>%
count(inclusive_teach_tokens, sort = TRUE)  %>%
summarise(totala = n())
df1 <- totaldeiarticle %>%
full_join(totalwordsarticle, by = c("article_num")) %>%
mutate(ratio = totaldeia/totala) %>%
group_by(Year)  %>%
rename("Article_Num" = "article_num",
"Total_DEI_1w" = "totaldeia",
"Total_1w" = "totala",
"DEItoTotal_Ratio_1w" = "ratio")
boxplot(df1$DEItoTotal_Ratio_1w ~ df1$Year, df1, xlab = "Year", ylab = "Ratio", main = "The Ratio of DEI Related Words to Total Words Over Time", horizontal = FALSE)
df1 %>%
count(Year, sort = TRUE)
#proportions for each year, fluctuating
totaldeiyear %>%
full_join(totalwordsyear, by = c("Year")) %>%
mutate(ratio = totaldeiy/totaly) %>%
ggplot(aes(Year, ratio)) +
geom_line() +
ylim(0,0.053) +
labs(y = "Ratio", title = "The Ratio of DEI Related Words to Total Words By Year", subtitle = "(in the 'Inclusive Teaching' Section)")
totaldeiyear %>%
full_join(totalwordsyear, by = c("Year")) %>%
mutate(ratio = totaldeiy/totaly)
#proportions for each year, fluctuating
totaldeiyear %>%
full_join(totalwordsyear, by = c("Year")) %>%
mutate(ratio = totaldeiy/totaly) %>%
ggplot(aes(Year, ratio)) +
geom_line() +
ylim(0,0.053) +
labs(y = "Ratio", title = "The Ratio of DEI Related Words to Total Words By Year", subtitle = "(in the 'Inclusive Teaching' Section)")
totaldeiyear %>%
full_join(totalwordsyear, by = c("Year"))
totaldeiyear %>%
full_join(totalwordsyear, by = c("Year")) %>%
mutate(ratio = totaldeiy/totaly)
totaldeiyear %>%
full_join(totalwordsyear, by = c("Year")) %>%
mutate(ratio = totaldeiy/totaly) %>%
ggplot(aes(Year, ratio)) +
geom_line()
#proportions for each year, fluctuating
totaldeiyear %>%
full_join(totalwordsyear, by = c("Year")) %>%
mutate(ratio = totaldeiy/totaly) %>%
ggplot(aes(Year, ratio)) +
geom_line() +
#ylim(0,0.053) +
labs(y = "Ratio", title = "The Ratio of DEI Related Words to Total Words By Year", subtitle = "(in the 'Inclusive Teaching' Section)")
#proportions for each article, also fluctuating (higher article # means it happened earlier ex: article # 270 = year 2014)
totaldeiarticle %>%
full_join(totalwordsarticle, by = c("article_num")) %>%
mutate(ratio = totaldeia/totala) %>%
arrange(article_num) %>%
ggplot(aes(article_num, ratio, color = Year)) +
geom_line() +
#ylim(0,0.053) +
labs(y = "Ratio", title = "The Ratio of DEI Related Words to Total Words By Article Number", subtitle = "(in the 'Inclusive Teaching' Section)", x = "Article Number") +
geom_smooth(method=lm, se=FALSE) +
scale_color_gradientn(colours = rainbow(9))
# rios_data_tokenizedit %>%
#   filter(article_num %in% c(120,171,197,220,242)) %>%
#   select(1,4,8:11)
library(readxl)
library(readxl)
X2DEI_new <- read_excel("2DEI_new.xlsx")
library(readxl)
X2DEI_prev <- read_excel("2DEI_prev.xlsx")
View(X2DEI_prev)
View(X2DEI_new)
left_join(X2DEI_new, X2DEI_prev, by = c("it_tokens_2w", "2DEI"))
left_join(X2DEI_new, X2DEI_prev, by = c("2DEI", "it_tokens_2w"))
?rename
rename(X2DEI_prev, it_tokens_2w = 2DEI)
rename(X2DEI_prev, "it_tokens_2w" = "2DEI")
left_join(X2DEI_new, X2DEI_prev, by = "it_tokens_2w")
X2DEI_prev <- rename(X2DEI_prev, "it_tokens_2w" = "2DEI")
left_join(X2DEI_new, X2DEI_prev, by = "it_tokens_2w")
updated_DEI <- left_join(X2DEI_new, X2DEI_prev, by = "it_tokens_2w")
View(updated_DEI)
updated_DEI %>%
filter(!is.na(updated_DEI$...3))
updated_DEI <- updated_DEI %>%
select(1,24)
select(1,2,4)
updated_DEI <- updated_DEI %>%
select(1,2,4)
write_csv(updated_DEI, "updated_DEI.csv")
sapply(stopwords_vec, function(x) any(sapply("as", str_detect, string = x)))
sum(sapply(stopwords_vec, function(x) any(sapply("as", str_detect, string = x))))
?str_detect
sapply(stopwords_vec, function(x) any(sapply("as ", str_detect, string = x)))
sapply(stopwords_vec, function(x) any(sapply("as", str_detect, string = x)))
sapply(stopwords_vec, function(x) any(sapply(" as", str_detect, string = x)))
sapply(stopwords_vec, function(x) any(sapply("for", str_detect, string = x)))
View(rios_data_token2it)
#most common DEI words
rios_2w_count <- rios_data_token2it %>%
filter(dei_related == "TRUE") %>%
count(it_tokens_2w, sort = TRUE)
write_csv(rios_2w_count, "rios2wcount.csv")
