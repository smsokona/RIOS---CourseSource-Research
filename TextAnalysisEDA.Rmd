---
title: "RIOS Research - Inclusive Teaching Text Analysis"
author: "Sokona Mangane"
date: "2022-12-14"
output:
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setup/Data Cleaning

Here I'm installing and loading the necessary packages and doing some data cleaning.

```{r Loading packages and data}

#cmd + shift + c to comment out code 
#cmd + shift + M to print %>% pipe operator
#cmd + return to run code 
#install.packages("skimr")
#install.packages("tidyverse")
#install.packages("tidytext")
#install.packages("stopwords")
#install.packages("wordcloud")
#install.packages("reshape2")
#install.packages("ggraph")
library(ggraph)
library(igraph)
library(skimr)
library(tidyverse)
library(tidytext)
library(ggplot2)
library(readr)
library(stopwords)
library(wordcloud)
library(reshape2)
rios_data <- read_csv("RIOS Research - Course Source - Sheet1 2.csv")
dei_keywords <- read_csv("SJEDI_words 2022-12-20 18_03_42.csv")
rios_data$`Inclusive Teaching  included?`[12] = "No"
rios_data <- rios_data %>%
  arrange(desc(Year))
```

I've created a variable with diversity related words from the keywords column and then added to the DEI Keywords that I imported `dei_keywords`. I also added another column, which includes the article number for each row.

```{r More Data Cleaning}
#diversity related words from the 'keyword themes' column!
diversity_related <- c("diversity", "bias", "confirmation bias", "cognitive bias", "social justice", "broader impacts", "racism", "identity", "equity", "inclusivity", "environmental justice", "inclusion", "belonging")

#adding the vector above to the CSV dei_keywords
for (x in 1:13){
  dei_keywords[nrow(dei_keywords) + 1,] = diversity_related[x]
}

rios_data$article_num <- c(1:nrow(rios_data))

Artlnumbyr <- rios_data %>%
  group_by(Year) %>%
  select(4,15) %>%
  summarise(artlsum = n()) %>%
  arrange(desc(Year))
```

Here, each word from the `Inlcusive Teaching Description` and `keyword themes` is "un-nested" into it's own row. Then any unnecessary punctuation, numbers and words are removed, for analysis.

```{r More Data Cleaning 2}

rios_data_tokenizedit <- rios_data %>%
  unnest_tokens(output = inclusive_teach_tokens, input = `Inclusive Teaching Description`)


#removing all rows with any punctuation, digits, or "stopwords" (~20k rows total)
strings <- c("[:punct:]", "[:digit:]","\\(","\\)")
stopwords_vec <- stopwords(language = "en")
stopwords_vec <- stopwords_vec[-c(165:167)]

#removed ~777 rows
rios_data_tokenizedit <- rios_data_tokenizedit %>%
  filter(!str_detect(inclusive_teach_tokens, paste(strings, collapse = "|")))

#removed ~19,663 rows
rios_data_tokenizedit <- rios_data_tokenizedit %>%
  filter(!inclusive_teach_tokens %in% stopwords_vec) 

#doing same thing as above but for keyword themes
rios_data_tokenizedkt <- rios_data %>%
  unnest_tokens(output = keyword_themes_tokens, input = `keyword themes`)


#removing all rows with any punctuation, digits, or "stopwords" (78 rows total)
strings <- c("[:punct:]", "[:digit:]","\\(","\\)")
stopwords_vec <- stopwords(language = "en")

#removed ~777 rows
rios_data_tokenizedkt <- rios_data_tokenizedkt %>%
  filter(!str_detect(keyword_themes_tokens, paste(strings, collapse = "|")))

#removed ~19,663 rows
rios_data_tokenizedkt <- rios_data_tokenizedkt %>%
  filter(!keyword_themes_tokens %in% stopwords_vec) 


```

## Exploratory Data Analysis

`dei_related` columns were created for each data frame, which says TRUE if that word (regarding the Inclusive Teaching Descriptions and the keyword themes) matches any word from the `dei_keywords` dataframe.

```{r EDA prep}

#creating a DEI related column
rios_data_tokenizedit$dei_relatedit = NA

rios_data_tokenizedkt$dei_relatedkt = NA

rios_data_tokenizedit$dei_relatedit <- sapply(rios_data_tokenizedit$inclusive_teach_tokens, function(x) any(sapply(dei_keywords, str_detect, string = x)))

rios_data_tokenizedkt$dei_relatedkt <- sapply(rios_data_tokenizedkt$keyword_themes_tokens, function(x) any(sapply(dei_keywords, str_detect, string = x)))

#save(dei_keywords, file = "dei_keywords.csv")
#saveRDS(rios_data_tokenized, file = "rios_data_tokenized.rds")

#removing the unnnecessary columns
rios_data_tokenizedit <- rios_data_tokenizedit[,-c(9:13)]
rios_data_tokenizedkt <- rios_data_tokenizedkt[,-c(9:13)]

```

# Basic Summary Statistics

What are the most common "DEI" Words in the Inclusive Teaching Description?

Looking at the most common DEI words gives us an idea of what DEI words are being used the most, and what does that tell us about how the authors are being inclusive. According to the table below, the words "inclusive", "diversity" and "diverse" are the most commons "DEI" words. This makes sense as inclusive teaching should be diverse and cater to a diversity of racial backgrounds. Out of 118 "DEI" distinct words used in the inclusive teaching text, note that 70% of these words are repeated more than once (83/118) and 54.2% are repeated more than twice (64/118). Based on these common words, it seems like these articles try to be inclusive by being diverse, engaging, and catering to a diverse set of backgrounds and abilities. Chunk 21 (Word Cloud) visualizes this clearly. 

However, the title of this section for which these descriptions are under is called "Inclusive teaching", so one could have a lengthy description under this section, without including any of the words from `dei_keywords` and then mention "inclusive teaching" to be included in this category, thus, these numbers may be an underestimate. Below (on Chunk 13 - 2 gram analysis) you can find a data frame `rios_2w_count` that portrays the most common DEI 2 words phrases.

[BASED ON WHAT WAS SAID ABOVE, FILTER FOR ALL THE PHRASES THAT DON'T MATCH "INCLUSIVE TEACHING" AND SEE HOW THIS NUMBER CHANGES]

```{r BSS1}
#BSS = BASIC SUMMARY STATISTICS

#most common DEI words, out of 118 (out of 4,464 words, 2.6% are DEI)
rios_data_tokenizedit %>%
  filter(dei_relatedit == "TRUE") %>%
  count(inclusive_teach_tokens, sort = TRUE)  
 
```

```{r BSS2}
#the most common dei_related words don't necessarily have the same dei related keyword themes
#rios_data_tokenizedkt %>%
 # filter(dei_relatedkt == "TRUE") %>%
  # group_by(keyword_themes_tokens) %>%
  # count(keyword_themes_tokens, sort = TRUE)

#saving for visuals on word counts, etc
it_word_counts <- rios_data_tokenizedit %>%
  filter(dei_relatedit == "TRUE") %>%
  group_by(Year) %>%
  count(inclusive_teach_tokens, sort = TRUE)
```

Which articles and years has the highest proportion of DEI related words? How does this proportion change?

I've calculated the number of *DISTINCT* DEI related words for each article and year. Then, I divided those numbers by the total amount of words for each article and year to get a proportion. Even though we have a word count column, I used the cleaned data frame `rios_data_tokenizedit` to calculate the total amount of words for a more "fair" comparison, thus the proportions may be an overestimate. Based on the plot, although the number of DEI related words is increasing each year, the proportions are decreasing, surprisingly...

```{r Proportion of DEI Words}
#totaldei for each year
totaldeiyear <- it_word_counts %>%
  summarise(totaldeiy = n()) 

#totaldei for each article, only 251 obs, so some articles don't have any dei related words (30 articles with no Inclusive Teaching Section...)
totaldeiarticle <- rios_data_tokenizedit %>%
  filter(dei_relatedit == "TRUE") %>%
  group_by(article_num, Year) %>%
  count(inclusive_teach_tokens) %>%
  summarise(totaldeia = n()) 

#total words in each year
totalwordsyear <- rios_data_tokenizedit %>%
  group_by(Year) %>%
  count(inclusive_teach_tokens, sort = TRUE)  %>%
  summarise(totaly = n())

#total words in each article, 
totalwordsarticle <-  rios_data_tokenizedit %>%
  group_by(article_num) %>%
  count(inclusive_teach_tokens, sort = TRUE)  %>%
  summarise(totala = n())
  

#proportions for each year, fluctuating 
totaldeiyear %>%
  full_join(totalwordsyear, by = c("Year")) %>%
  mutate(ratio = totaldeiy/totaly) %>%
  ggplot(aes(Year, ratio)) +
  geom_line() +
  ylim(0,0.053) +
  labs(y = "Ratio", title = "The Ratio of DEI Related Words to Total Words By Year", subtitle = "(in the 'Inclusive Teaching' Section)")
```

I decided to group by article number so I could get a better, more detailed look at the changes in the proportions. We can see that certain articles are outliers, with the highest in 2014 and average ratio being just over 0.05. Notice for articles 120, 171, 197, 220, and 242 there are no diversity related words and that's why there are "blanks" in the graph.

Looking at proportions gives us an idea of how many DEI words are being used and if there is a change over time. Based on the calculation above, only 2.6% of words in the Inclusive Teaching Text are DEI related (118/4,464). However, this doesn't necessarily mean that the article isn't being inclusive. Additionally, since we're looking grouping the data by year and article, the total DEI words for each year and article will be higher than 118, as some words are used in multiple years/articles.

```{r Proportion of DEI Words 2}

#proportions for each article, also fluctuating (higher article # means it happened earlier ex: article # 270 = year 2014)
totaldeiarticle %>%
  full_join(totalwordsarticle, by = c("article_num")) %>%
  mutate(ratio = totaldeia/totala) %>%
  arrange(article_num) %>%
  ggplot(aes(article_num, ratio, color = Year)) +
  geom_line() +
  #ylim(0,0.053) +
  labs(y = "Ratio", title = "The Ratio of DEI Related Words to Total Words By Article Number", subtitle = "(in the 'Inclusive Teaching' Section)", x = "Article Number") +
  geom_smooth(method=lm, se=FALSE) + 
  scale_color_gradientn(colours = rainbow(9))




# rios_data_tokenizedit %>%
#   filter(article_num %in% c(120,171,197,220,242)) %>%
#   select(1,4,8:11)


```

# Visuals :)

## Word Count of Inclusive Teaching Text Over Time Box Plot

The boxplot below just visualizes the word count of the Inclusive Teaching Section over time, which we can see is similar to the trend of the total DEI related words over time.

```{r V1}
#word count over time plot 
#rios_data %>%
 # ggplot(aes(rios_data$Year, rios_data$`Word Count of Inclusive Teaching?`)) + 
  #  geom_boxplot(na.rm = TRUE) +
   # labs(x = "Year", y = "Word count of Inclusive Teaching Section",
  #title = "Word Count of Inlcusive Teaching Sections Over Time")


  boxplot(`Word Count of Inclusive Teaching?`~Year,
          data=rios_data,
          main="Word Count of Inlcusive Teaching Sections Over Time",
          xlab="Year",
          ylab="Word count of Inclusive Teaching Section",
          horizontal = TRUE)



```

## In Depth Bar Chart of Word Count By Year {.tabset}

This is a bar chart that looks more in depth into the frequency of words being used, each year. You can click on each tab to see to compare by each year. Keep in mind, more words are shown from 2014-2019 compared to the years after it. Regardless, when we compare each chart we can see that the number and diversity of words increases (there are decreases in 2018, and 2021) each year. From the top 20 for each year, the words "diverse", "diversity", "engage", "individual", and "inclusive" are being used the most. 

### 2014

```{r V2 2014, warning=FALSE}

it_word_counts %>%
  filter(Year == 2014) %>%
  top_n(20) %>%
  ggplot(aes(inclusive_teach_tokens, n)) + 
  geom_bar(stat = "identity", show.legend = FALSE) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ylim(0,33)
```

### 2015

```{r V2 2015, warning=FALSE}

it_word_counts %>%
  filter(Year == 2015) %>%
  top_n(20) %>%
  ggplot(aes(inclusive_teach_tokens, n)) + 
  geom_bar(stat = "identity", show.legend = FALSE) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ylim(0,33)
```

### 2016

```{r V2 2016, warning=FALSE}

it_word_counts %>%
  filter(Year == 2016) %>%
  top_n(20) %>%
  ggplot(aes(inclusive_teach_tokens, n)) + 
  geom_bar(stat = "identity", show.legend = FALSE) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ylim(0,33)
```

### 2017

```{r V2 2017, warning=FALSE}

it_word_counts %>%
  filter(Year == 2017) %>%
  top_n(20) %>%
  ggplot(aes(inclusive_teach_tokens, n)) + 
  geom_bar(stat = "identity", show.legend = FALSE) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ylim(0,33)
```

### 2018

```{r V2 2018, warning=FALSE}

it_word_counts %>%
  filter(Year == 2018) %>%
  top_n(20) %>%
  ggplot(aes(inclusive_teach_tokens, n)) + 
  geom_bar(stat = "identity", show.legend = FALSE) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ylim(0,33)
```

### 2019

```{r V2 2019, warning=FALSE}

it_word_counts %>%
  filter(Year == 2019) %>%
  top_n(20) %>%
  ggplot(aes(inclusive_teach_tokens, n)) + 
  geom_bar(stat = "identity", show.legend = FALSE) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ylim(0,33)
```

### 2020

```{r V2 2020, warning=FALSE}

it_word_counts %>%
  filter(Year == 2020) %>%
  top_n(20) %>%
  ggplot(aes(inclusive_teach_tokens, n)) + 
  geom_bar(stat = "identity", show.legend = FALSE) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ylim(0,33)
```

### 2021

```{r V2 2021, warning=FALSE}

it_word_counts %>%
  filter(Year == 2021) %>%
  top_n(20) %>%
  ggplot(aes(inclusive_teach_tokens, n)) + 
  geom_bar(stat = "identity", show.legend = FALSE) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ylim(0,33)
```

### 2022

```{r V2 2022, warning=FALSE}

it_word_counts %>%
  filter(Year == 2022) %>%
  top_n(20) %>%
  ggplot(aes(inclusive_teach_tokens, n)) + 
  geom_bar(stat = "identity", show.legend = FALSE) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ylim(0,33)
```

##  {-}



```{r V3}
#Better (w/o facet wrap), but only includes \~22% of data! (b/c we filtered for n \> 5)

#it_word_counts %>%
 # filter(n > 5) %>%
  #mutate(inclusive_teach_tokens = reorder(inclusive_teach_tokens, n)) %>%
  #ggplot(aes(inclusive_teach_tokens, n, fill = Year)) +
  #geom_col() +
  #coord_flip() +
  #labs(y = "(DEI Related) Word Count in Inclusive Teaching Text") +
  #facet_wrap(~Year)
```

## WordClouds

Word clouds are another way of visualizing which words are being used the most. This word cloud shows distinct words to create the word cloud to avoid any repetitions. The wordcloud visualizes what we saw in chunk 6. 

```{r V4, warning = FALSE}

rios_data_tokenizedit %>%
  filter(dei_relatedit == "TRUE") %>%
  count(inclusive_teach_tokens, sort = TRUE) %>% 
  with(wordcloud(inclusive_teach_tokens, n))
```

```{r V5}

#??? Too many years! and not color blind friendly

# it_word_counts %>%
#   acast(inclusive_teach_tokens ~ Year, value.var = "n", fill = 0) %>%
#   comparison.cloud(colors = c("#fbb4ae", "#b3cde3", "#ccebc5", "#decbe4", "#fed9a6", "#ffffcc", "#e5d8bd", "#fddaec", "#f2f2f2"))

```

# 2-gram Word Analysis

The tables and visuals above give us an idea of how often are DEI Words used and what does that say about inclusivity of the articles. However, looking at the most commonly used DEI words doesn't give us all the information on how the article is being inclusive and their definitions of it. Thus, I'll repeat the analyses I did above, but looking at phrases, specifically of 2 words. Unlike above, I looked through all the phrases and removes what I felt was unnecessary and/or didn't make sense.



```{r 2-gram word analysis prep}


rios_data_token2it <- rios_data %>%
  unnest_tokens(it_tokens_2w, `Inclusive Teaching Description`, token = "ngrams", n = 2)  %>%
  separate(it_tokens_2w, c("word1", "word2"), sep = " ")

rios_data_token2it <- rios_data_token2it %>%
  filter(!word1 %in% stopwords_vec) %>%
  filter(!word2 %in% stopwords_vec) %>% 
  unite(it_tokens_2w, word1, word2, sep = " ") 

rios_data_token2it <- rios_data_token2it %>%
  filter(!str_detect(it_tokens_2w, paste(strings, collapse = "|")))


#creating a DEI related column
rios_data_token2it$dei_related = NA


rios_data_token2it$dei_related <- sapply(rios_data_token2it$it_tokens_2w, function(x) any(sapply(dei_keywords, str_detect, string = x)))


#removing the unnnecessary columns/rows [doesn't make sense or not related to DEI] 
#however keep in mind, in the context of a sentence it probably make senses, so i could be removing some important words

rios_data_token2it <- rios_data_token2it[,-c(9:13)]

unnecessary <- c("individually table", "individual investigators", "individual module", "individual noninteractive", "individual pre", "individual clicker", "inclusion another", "inclusion additionally", "identify species", "identify primer", "identify possible", "identified alternatively", "identification", "ideas individual", "group divide", "general inclusive", "bird identification", "yet inclusive", "variants identified", "teachers identify", "skills perspectives", "sheet individually", "residential birds", "radiation incidents", "regular individually", "pipeline cure", "plant communities", "popular culture", "personal connection", "physical connection", "perspective remind", "perspectives anonymous", "four individuals", "first collaborative", "find identify", "ever identified", "evenly divides", "ethnic economic", "ethnic given", "equity public", "england individual", "engaging final", "diverse face", "diverse natural", "diverse mixed", "direct connection", "disabilities benefit", "data individuals", "data individually", "less confident", "communities due", "collaborative yet", "collaborative easing", "collaboration using", "collaboration throughout", "class individual", "biodiversiy lab", "biodiversity losses", "backgrounds may", "backgrounds find", "backgrounds furthermore", "backgrounds therefore", "area identified", "answer individually", "agricultural sciences", "ability train", "ability moreover", "abilities match", "questions individually", "individuals turn", "individuals since", "communicate collaborate", "backgrounds throughout", "access see", "ada accessibility", "de identified", "efficacy identity", "individualactors may")

rios_data_token2it <- rios_data_token2it %>%
  filter(!str_detect(it_tokens_2w, paste(unnecessary, collapse = "|")))

```

Here we have printed the most common DEI phrases, similar to what we did in Chunk 6 and a visualization of those phrases. Although some of the phrases aren't repeated often, they are definition of inclusive teaching goes beyond just engaging all students.

``` {r 2gwa bss 1}
#most common DEI words
rios_2w_count <- rios_data_token2it %>%
  filter(dei_related == "TRUE") %>%
  count(it_tokens_2w, sort = TRUE) 


#graph of that 
rios_2w_count %>%
  top_n(30) %>%
  mutate(it_tokens_2w = reorder(it_tokens_2w, n)) %>%
  ggplot(aes(it_tokens_2w, n)) +
  geom_col() +
  coord_flip() +
  labs(y = "(DEI Related) 2 Word Count in Inclusive Teaching Text") + 
  xlab(NULL)
```

When we look at the propotion of DEI phrases they're increasing, unlike our plot in Chunk 8...


``` {r Proportions of DEI Phrases}

#total2dei for each year
total2deiyear <- rios_data_token2it %>%
  filter(dei_related == "TRUE") %>%
  group_by(Year) %>%
  count(it_tokens_2w, sort = TRUE) %>%
  summarise(totaldeiy = sum(n))

#total2dei for each article, only 240 obs vs 251!
total2deiarticle <- rios_data_token2it %>%
  filter(dei_related == "TRUE") %>%
  group_by(article_num, Year) %>%
  count(it_tokens_2w, sort = TRUE) %>%
  summarise(totaldeia = sum(n)) %>%
  arrange(desc(totaldeia))

# #total words in each year
# total2wordsyear <-  rios_data_token2it %>%
#   group_by(Year) %>%
#   count(it_tokens_2w, sort = TRUE)  %>%
#   summarise(totaly = n())

#na.rm = TRUE))

#total words in each article
# totalwordsarticle <- rios_data %>%
#   select(15,9)
  

#proportions for each year, fluctuating like before
total2deiyear %>%
  full_join(totalwordsyear, by = c("Year")) %>%
  mutate(ratio = totaldeiy/totaly)%>%
  arrange(desc(ratio)) %>%
  ggplot(aes(Year, ratio)) +
  geom_line() +
  ylim(0,0.143) +
  labs(y = "Ratio", title = "The Ratio of DEI Related Phrases to Total Words By Year", subtitle = "(in the 'Inclusive Teaching' Section)")
```

Similarly, despite the outlier ratio in 2019, we see a slight downward trend here as well, meaning that the ratio of DEI related phrases decrease as the year decreases (and the article number increases).


``` {r Proportions of DEI Phrases 2}
#proportions for each article, also fluctuating
total2deiarticle %>%
  full_join(totalwordsarticle, by = c("article_num")) %>%
  mutate(ratio = totaldeia/totala) %>%
  arrange(desc(ratio))  %>%
  ggplot(aes(article_num, ratio, color = Year)) +
  geom_line() +
  #ylim(0,0.053) +
  labs(y = "Ratio", title = "The Ratio of DEI Related Phrases to Total Words By Article Number", subtitle = "(in the 'Inclusive Teaching' Section)", x = "Article Number") +
  geom_smooth(method=lm, se=FALSE) + 
  scale_color_gradientn(colours = rainbow(9))



```

The visuals above give us an idea of what words are used most frequently and how that has changed over time. We can definitely see what people view as inclusive teaching has changed but still varies. However, to reiterate the frequency of . 


# 3 gram Word Analysis

I also did a 3 gram word Analysis, which has a much a lower frequency. However, this gives us a better idea of what "inclusive teaching" means in these contexts. 
```{r 3gwa}

## plot the frequency
prof.count %>% filter(n > 50) %>% mutate(word = reorder(word, n)) %>% ggplot(aes(word, 
    n)) + geom_col() + xlab(NULL) + coord_flip()


rios_data_token3it <- rios_data %>%
  unnest_tokens(it_tokens_3w, `Inclusive Teaching Description`, token = "ngrams", n = 3)  %>%
  separate(it_tokens_3w, c("word1", "word2", "word3"), sep = " ")

rios_data_token3it <- rios_data_token3it %>%
  filter(!word1 %in% stopwords_vec) %>%
  filter(!word2 %in% stopwords_vec) %>%
  filter(!word3 %in% stopwords_vec) %>%
  unite(it_tokens_3w, word1, word2, word3, sep = " ") 

rios_data_token3it <- rios_data_token3it %>%
  filter(!str_detect(it_tokens_3w, paste(strings, collapse = "|")))


#creating a DEI related column
rios_data_token3it$dei_related = NA


rios_data_token3it$dei_related <- sapply(rios_data_token3it$it_tokens_3w, function(x) any(sapply(dei_keywords, str_detect, string = x)))


#removing the unnnecessary columns/rows
rios_data_token3it <- rios_data_token3it[,-c(9:13)]

#removing unnecessary content that doesn't make sense, however keep in mind as three words it might not make sense or be related to inclusive teaching, but in the context of a sentence it probably make sense

unnecessary2 <- c("academic background identity", "academic professional backgrounds", "individuals since questions", "inclusive teaching requires", "implements inclusive teaching", "many individuals since", "must communicate collaborate", "several inclusive teaching", "abilities experimental questions", "access discussion throughout", "access faculty access", "access sample work", "access see comments", "access several learning", "access software programs", "access species database", "accommodators perceived individual", "animal communities due", "american cultures science", "author backgrounds demonstrating", "background knowledge differently", "background therefore inexpensive", "backgrounds can benefit", "backgrounds find intellectual", "backgrounds may identify", "backgrounds needs learning", "backgrounds often find", "biodiversity database schools", "biodiversity lab report", "biodiversity losses amount", "biology species identified", "bird identification resources", "broader area identified", "butterfly activity engages", "campus based access", "class individual research", "class collaboration peer", "class individual research", "clicker questions individually", "coast students connected", "collaborative effort seeks", "completed courses backgrounds", "completing individual work", "connected device instructors", "connections may result", "contribute individual data", "cultured bacteria including", "cures increase access", "current biodiversity losses", "cyverse infrastructure connected", "de identified results", "different communities may", "disabilities additionally scientific", "discussing cellular diversity", "diverse demonstrators finally", "diversity among streptomyces", "diversity dna sequence", "diversity gap additionally", "divides labor among", "drift engaging students", "dynamics inclusive learning", "engagement student appropriate", "engages multiple senses", "engaging final presentation", "engaging multiple types", "engaging multiple week", "england individual investigators", "evenly divides labor", "friendly internet connected", "genetic drift engaging", "handle cultured samples", "handling cultured bacteria", "high impact active", "ideas individual writing", "identified asset maps", "identified instructors implementing", "identified personality types", "identify possible therapeutic", "identify primer binding", "inclusion another way", "inclusion standards can", "inclusion within many", "individual choice udl", "individual clicker questions", "individual self paced", "individual pre class", "individual submissions upon", "individual writing assignments", "ndividual writing peer", "individual written report", "individually completing separate", "individually first although", "individually group work", "individually providing time", "individually select groups", "individually selected research", "individuals students work", "instructor individual exploration", "instructor individual pre", "interesting biological cultural", "internet connected device", "investigate genetic diversity", "loxp lesson inclusive", "microorganisms impact human", "might impact human", "natural abilities match", "nuclear radiation incidents", "online bird identification", "open access species", "perspectives anonymous clicker", "plant communities useful", "plant identification http", "practice sheet individually", "prefer individual work", "project biodiversify website", "public biodiversity database", "purposes open access", "pursuing bird identification", "questions individual students", "questions individually discuss", "regular individually selected", "reliable internet connectivity", "revealing identifying information", "rgs encourage individual", "seafood traceability issues", "self efficacy identity", "self identified asset", "self identified personality", "serpentine plant communities", "sheet individually providing", "significantly less connected", "simple model collaboration",	"site easily accessible", "spatial ability train", 
"species identified alternatively",	"species identified instructors", "strategies including individual", "traceability issues overall", "videos students engage", "ways first collaborative", "ways individual clicker", "ways individual self", "whether current biodiversity")
#didn't include all of them here, but notice that inclusive teaching is synonmous with collaborative, working with other students (rows 123-144), being diverse, diversity (rows 198-237), and including ppl (inclusion, inclusive, including, etc.)

rios_data_token3it <- rios_data_token3it %>%
  filter(!str_detect(it_tokens_3w, paste(unnecessary2, collapse = "|")))


#graph of the most common
rios_data_token3it %>%
  filter(dei_related == "TRUE") %>%
  count(it_tokens_3w, sort = TRUE) %>%
  top_n(30) %>%
  mutate(it_tokens_3w = reorder(it_tokens_3w, n)) %>%
  ggplot(aes(it_tokens_3w, n)) +
  geom_col() +
  coord_flip() +
  labs(y = "(DEI Related) 3 Word Count in Inclusive Teaching Text") + 
  xlab(NULL)
```

Just like the DEI phrases of 2 words, we can see that the proportions are increasing every year, with the highest proportion in 2020!

``` {r Proportions of DEI Phrases 3w}

#total3dei for each year
total3deiyear <- rios_data_token3it %>%
  filter(dei_related == "TRUE") %>%
  group_by(Year) %>%
  count(it_tokens_3w, sort = TRUE) %>%
  summarise(totaldeiy = sum(n))

#total2dei for each article, now 189 obs vs 251 and 240!
total3deiarticle <- rios_data_token3it %>%
  filter(dei_related == "TRUE") %>%
  group_by(article_num, Year) %>%
  count(it_tokens_3w, sort = TRUE) %>%
  summarise(totaldeia = sum(n)) %>%
  arrange(desc(totaldeia))

# #total words in each year
# total2wordsyear <-  rios_data_token2it %>%
#   group_by(Year) %>%
#   count(it_tokens_2w, sort = TRUE)  %>%
#   summarise(totaly = n())

#na.rm = TRUE))

#total words in each article
# totalwordsarticle <- rios_data %>%
#   select(15,9)
  

#proportions for each year, fluctuating like before
total3deiyear %>%
  full_join(totalwordsyear, by = c("Year")) %>%
  mutate(ratio = totaldeiy/totaly)%>%
  arrange(desc(ratio)) %>%
  ggplot(aes(Year, ratio)) +
  geom_line() +
  ylim(0,0.143) +
  labs(y = "Ratio", title = "The Ratio of DEI Related Phrases (3 Words) to Total Words By Year", subtitle = "(in the 'Inclusive Teaching' Section)")
```



There are a lot of breaks in our graph compared to the other two graphs, but this showcases a trend of the proportion decreasing.

``` {r Proportions of DEI Phrases 3w 2}
#proportions for each article, also fluctuating
total3deiarticle %>%
  full_join(totalwordsarticle, by = c("article_num")) %>%
  mutate(ratio = totaldeia/totala) %>%
  arrange(desc(ratio))  %>%
  ggplot(aes(article_num, ratio, color = Year)) +
  geom_line() +
  #ylim(0,0.053) +
  labs(y = "Ratio", title = "The Ratio of DEI Related Phrases (3 words) to Total Words By Article Number", subtitle = "(in the 'Inclusive Teaching' Section)", x = "Article Number") +
  geom_smooth(method=lm, se=FALSE) + 
  scale_color_gradientn(colours = rainbow(9))



```

# Network Plot of Word Relationship

To get a deeper understanding of how inclusive teaching is viewed, we will be creating a network plot to look at the relationship between words/phrases in the inclusive teaching section. The generated `igraph` graph is called `rios_phrase_network`. It has 41 words and 36 connections among them. Similar to what some of our graphs have portrayed above, the words "inclusive", "students", and "diverse" are connected to many other words

```{r}
rios_data_token2 <- rios_data_token2it %>%
  separate(it_tokens_2w, c("word1", "word2"), sep = " ")

rios_phrase_network <- rios_data_token2 %>% 
  filter(dei_related == TRUE) %>%
  count(word1, word2, sort = TRUE) %>% 
  filter(n > 3) %>% 
  graph_from_data_frame()


set.seed(20181005)

a <- arrow(angle = 30, length = unit(0.1, "inches"), ends = "last", type = "open")

ggraph(rios_phrase_network, layout = "fr") + geom_edge_link(aes(color = n, width = n), arrow = a) + 
    geom_node_point() + geom_node_text(aes(label = name), vjust = 1, hjust = 1)

```



# Normalized Word Frequency 

This can help us see the "weight" of each words and the words most distinctive for each year and article

```{r norm word freq}

#finding the most distinctive words for each document
it_word_counts %>%
  bind_tf_idf(inclusive_teach_tokens, Year, n) %>%
  arrange(desc(tf_idf))

rios_data_tokenizedit %>%
  filter(dei_relatedit == "TRUE") %>%
  group_by(article_num, Year) %>%
  count(inclusive_teach_tokens, sort = TRUE) %>%
  bind_tf_idf(inclusive_teach_tokens, article_num, n) %>%
  arrange(desc(tf_idf))

```







